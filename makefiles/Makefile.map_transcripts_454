################################################################################
#   Gene prediction pipeline 
#
#   $Id: Makefile.map_transcripts_454 2781 2009-09-10 11:33:14Z andreas $
#
#   Copyright (C) 2005 Andreas Heger
#
#   This program is free software; you can redistribute it and/or
#   modify it under the terms of the GNU General Public License
#   as published by the Free Software Foundation; either version 2
#   of the License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
#################################################################################
#################################################################################
#################################################################################
##
## Map and assemble 454 reads from a cDNA library
##
## Usage:
##   1. Preparations
##
##      1. Check out code
##
##        svn co svn://fgu202/andreas/gpipe/trunk src 
##
##      2. Create makefile:
##
##        python src/gpipe/setup.py -m map_transcripts_454 -d . > setup.log
##
##      3. Add or link fasta files of reads into directory. These should end
##          with the suffix .fasta. The pipeline will process several files at the same time.
##	    For example:
##             tissue1.fasta
##             tissue2.fasta
##             tissue3.fasta
##
##      4. Link towards the genome from /net/cpp-data/backup/databases/indexed_fasta and
##      call the files genome.fasta and genome.idx. For example:
##       
##	  ln -s /net/cpp-data/backup/databases/indexed_fasta/hs_ncbi36_softmasked.fasta genome.fasta
##        ln -s /net/cpp-data/backup/databases/indexed_fasta/hs_ncbi36_softmasked.idx genome.idx
##
##      5. Make sure that the index for the genome has been built in gmap.
##      If not, run gmap_setup. Provide the location to the indices using
##      the variable PARAM_GMAP_OPTIONS. 
##	Note: I found that it is good to have the indices locally so I copy them
##      over from the central repository when needed. Thus the
##      makefile looks in the current directory for the indices per default.
##      Delete the obsolete local copies of indices when finished.
##
##   2. Running
##      
##	Type:
##
##         nice -19 nohup make -j ## all
##
##	where ## is the number of jobs you want to run at the same time. This
##      will typically be the number of samples you process.
##
##   3. Results
##
##      With the example above, output files will be named tissue.%
##
##      The following principal output files will be created:
##         %.gmap: gmap mapping results for all reads.
##         %.filter: mapped reads after filtering.
##         %.transcripts: output after assembling transcripts on genome.
##         %.gtf: assembled transcripts in gtf format.
##
##   How to view the results in the ucsc browser:
##   1. set PARAM_PROJECT_NAME to something meaningfull to avoid overwriting other
##       files
##
##   2. make sure that the directory ~/public_html/ucsc_tracks exists.
##
##   3. depending on which stage you want to view, type for all tracks:
##       make ucsc-tracks-mapped
##      or
##       make ucsc-tracks-filtered
##      or 
##       make ucsc-tracks-assembled
## 
##   Load the custom track in the ucsc genome browser by pasting the echoed URL.
##   Note these files can be quite large and take a while to upload to the ucsc 
##   browser. To view individal tracks, type:
##
##      make tissue1.ucsc-track-mapped
##      make tissue1.ucsc-track-filtered
##      make tissue1.ucsc-track-assembled
##
#################################################################################

################################################
## Section parameters: start
################################################
## project name
PARAM_PROJECT_NAME?=map454
################################################

PARAM_GENOME?=pa_ponAbe2

################################################
## mapping method. Currently implemented are
## gmap
## blat: make sure that the server is started on port 8000
PARAM_MAPPING_METHOD?=gmap

PARAM_GMAP_OPTIONS?=-D . 

################################################
## BLAT: host name where server runs
PARAM_BLAT_HOST?=fgu204
## BLAT: port where server runs
PARAM_BLAT_PORT?=8000
## BLAT: database with location of nib files
PARAM_BLAT_DB?=/net/cpp-mirror/databases/blat/human_ncbi_36
## BLAT: command line options to gfClient
PARAM_BLAT_OPTIONS?=

################################################
## minimim query coverage - all matches with less are ignored
## unless --keep-unique-matches is set
PARAM_MIN_QUERY_COVERAGE?=90

################################################
## minimum number of matching aligned residues
PARAM_MIN_MATCHES?=50

################################################
## Number of high-level parallel jobs
PARAM_PARALLEL?=20

################################################
## if given, compute location of gene set with reference set
PARAM_REFERENCE_SET?=

################################################
## method to rank matches
PARAM_FILTER_MATCHING_MODE?=best-query-covpid

################################################
## difference between best match and second best match (relative) to accept
## the best match as unique. Set to 0 to include all matches.
## This filter acts in conjunction with PARAM_FILTER_COLLECTION_DISTANCE.
PARAM_FILTER_COLLECTION_THRESHOLD?=0.9

################################################
## difference between best match and second best (absolute) to accept
## the best match as unique. Set to a large value to include all matches.
## This filter acts in conjunction with PARAM_FILTER_COLLECTION_THRESHOLD.
PARAM_FILTER_COLLECTION_DISTANCE?=0

################################################
## derived sets - excluded from some analyses
PARAM_DERIVED_SETS?=

################################################
## options to filter with
PARAM_FILTER_OPTIONS?=--matching-mode=$(PARAM_FILTER_MATCHING_MODE) \
		--threshold-min-query-coverage=$(PARAM_MIN_QUERY_COVERAGE) \
		--collection-threshold=$(PARAM_FILTER_COLLECTION_THRESHOLD) \
		--collection-distance=$(PARAM_FILTER_COLLECTION_DISTANCE) \
		--keep-unique-matches \
		--threshold-min-matches=$(PARAM_MIN_MATCHES)


################################################
## options for assembly of transcripts into reads
PARAM_TRANSCRIPTS_OPTIONS?=--staggered=all \
		--method=region \
		--method=transcript \
		--method=coverage \
		--method=polyA \
		--threshold-merge-distance=0 \
		--threshold-merge-overlap=3 \
		--filter=exon-extenders \
		--filter=transcript-mergers \
		--filter=duplicates


################################################
## set to value, if you want to perform the assembly step
PARAM_DO_ASSEMBLY?=1

################################################
# Section parameters: end
################################################


FASTA=$(wildcard *.fasta)
READS=$(filter-out %.psl.fasta genome.fasta, $(FASTA))
READS_RAW=$(filter-out %.psl.fasta genome.fasta all.fasta, $(FASTA))
INPUT=$(READS:%.fasta=%)
INPUT_RAW=$(READS_RAW:%.fasta=%)
INPUT_NONDERIVED=$(filter-out $(PARAM_DERIVED_SETS), $(INPUT_RAW))
TRANSCRIPTS=$(READS:%.fasta=%.transcripts)
MAPPED=$(READS:%.fasta=%.$(PARAM_MAPPING_METHOD))
FILTERED=$(READS:%.fasta=%.filter)
GTFS=$(READS:%.fasta=%.gtf)

## username
USER=$(shell whoami)

all: run build import

##################################################################
##################################################################
##################################################################
run: 
	$(MAKE) -j $(PARAM_PARALLEL) map filter transcripts gtf 

build: run
	$(MAKE) -j $(PARAM_NUM_JOBS) full-build

import: build full-import

filter-gtf: $(READS:%.fasta=%_filter.gtf) $(READS:%.fasta=%_filter.coverage)

##################################################################
##################################################################
##################################################################
## secondary mapping and assembly targets
##################################################################
map: $(MAPPED)
filter: $(FILTERED)
transcripts: $(TRANSCRIPTS)
gtf: $(GTFS)

.PHONY: filter transcripts gtf run build import

##################################################################
##################################################################
##################################################################
## secondary build targets
##################################################################
full-build: filterstats-build readstats-build alignstats-build readpos-build filterbedgraph-build 
full-import: full-build filter-import transcripts-import readstats-import filterstats-import readpos-import alignstats-import

##################################################################
##################################################################
##################################################################
## perform analysis after computation
##################################################################
analysis: readstats readpos summary.table plots

##################################################################
##################################################################
##################################################################
## import statements
##################################################################
filterstats-build: $(FILTERED:%.filter=%.filterstats)
filterstats-import: $(FILTERED:%.filter=%_filterstats.import)

readstats-build: $(READS:%.fasta=%.readstats)
readstats-import: $(READS:%.fasta=%_readstats.import)

alignstats-build: $(MAPPED:%.$(PARAM_MAPPING_METHOD)=%.alignstats)
alignstats-import: $(MAPPED:%.$(PARAM_MAPPING_METHOD)=%_alignstats.import)

filter-import: $(FILTERED:%.filter=%_filter.import)
transcripts-import: $(TRANSCRIPTS:%.transcripts=%_transcripts.import)

filterbedgraph-build: $(FILTERED:%.filter=%_filter.bedgraph.gz)

##################################################################
##################################################################
##################################################################
## compute statistics on postitions of reads.
##################################################################
ifneq ($(PARAM_REFERENCE_SET),)
readpos-build: $(READS:%.fasta=%.readpos)
readpos-import: $(READS:%.fasta=%_readpos.import)
else
readpos-build:
readpos-import:
endif

##################################################################
##################################################################
##################################################################
## create plots
##################################################################
plots: coverage_mean.png coverage_median.png pgc.png \
	read_length.png \
	read_length_eliminated.png read_length_accepted.png \
	missing_residues.plots \
	duplicates.png

clean-plots:
	rm -f *.png missing_residues.plots

##################################################################
##################################################################
##################################################################
## print summary of mapping runs for all datasets
##################################################################
print-summary: $(READS:%.fasta=%.summary)

##################################################################
##################################################################
##################################################################
## create all.fasta
##################################################################
all.fasta: 
	$(PRELOG)
	@python $(DIR_SCRIPTS_TOOLS)index_fasta.py \
		--allow-duplicates all $(READS_RAW) > $@.log
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Align reads to genome
##################################################################
## gmap chops off chr in its index - re-attach it.
%.gmap: %.fasta
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) -l mem_free=4000M \
	$(CMD_BENCHMARK) --log=$@.log \
	"gmap -B 1 $(PARAM_GMAP_OPTIONS) -d $(PARAM_GENOME) -A -f 1 -t 2 $< > $@.tmp 2> $@.log" < /dev/null >> $@.log
	@awk -v OFS="\t" '$$14 !~ /^[cC]hr/ && $$14 !~ /[sScaffold]/ && $$14 !~ /[cC]ontig/ { $$14 = sprintf("chr%s",$$14) } { print; }' < $@.tmp > $@
	@rm -f $@.tmp
	$(EPILOG)

%.blat: %.fasta
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) \
	gfClient -q=dna $(PARAM_BLAT_OPTIONS) $(PARAM_BLAT_HOST) $(PARAM_BLAT_PORT) $(PARAM_BLAT_DB)  $< $@ > $@.log	
	$(EPILOG)

%.xblat: %.fasta
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) blat -q=dna -t=dna genome.fasta $< $@ < /dev/null > $@.log	
	$(EPILOG)

.PRECIOUS: %.gmap %.blat %.xblat 

##################################################################
##################################################################
##################################################################
## Remove bad/ambiguous reads
##################################################################
%.filter: %.$(PARAM_MAPPING_METHOD)
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) \
	python $(DIR_SCRIPTS_GENEPREDICTION)blat2map.py \
		$(PARAM_FILTER_OPTIONS) \
		--output-filename-pattern=$@.%s \
		--output-format=blat \
		--output-filename-empty=$@.empty \
		--polyA \
		--input-filename-queries=$* \
		--log=$@.log \
	< $< > $@
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Import results from filtering stage
##################################################################
%_filter.import: %.filter
	$(PRELOG)
	@csv2db.py --map read_id:str -b sqlite --index=read_id --table=$*_filterempty < $<.empty > $@
	$(EPILOG)


##################################################################
##################################################################
##################################################################
## Compute read statistics
##################################################################
%.readstats: %.fasta
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) \
	python $(DIR_SCRIPTS_GENEPREDICTION)analyze_codonbias_shannon.py \
		--log=$@.log \
		--sections=length,na,hid --regex-identifier='"(\S+)"' < $< > $@
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Import read statistics
##################################################################
%_readstats.import: %.readstats
	$(PRELOG)
	@perl -p -e "s/^id/read_id/" < $< | grep -v "^total" |\
	csv2db.py --map gene_id:str -b sqlite --index=read_id --table=$*_readstats > $@
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Compute location of matches with a reference gene set
##################################################################
%.readpos: %.filter $(PARAM_REFERENCE_SET)
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) \
	"python $(DIR_SCRIPTS_GENEPREDICTION)blat2gff.py --log=$@.log --as-gtf < $< > $@.tmp" < /dev/null
	@$(CMD_REMOTE_SUBMIT) \
	"python $(DIR_SCRIPTS_GENEPREDICTION)gtf2table.py \
		--log=$@.log \
		--counter=length \
		--counter=coverage \
		--counter=overlap \
		--filename-gff=$@.tmp \
	< $(PARAM_REFERENCE_SET) > $@" < /dev/null
	@rm -f $@.tmp
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Import location of matches with a reference gene set
##################################################################
%_readpos.import: %.readpos
	$(PRELOG)
	@csv_cut --large -r cov_values < $< |\
	csv2db.py --map gene_id:str -b sqlite --index=gene_id --table=$*_readpos > $@
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Assemble into transcripts
##################################################################
ifneq ($(PARAM_DO_ASSEMBLY),)
%.transcripts: %.filter
	$(PRELOG)
	@if test -e $*.idx; then \
		transcripts_extra_options=--input-filename-queries=$*; \
	fi; \
	awk '/psLayout/ { x = 4; next; } x > 0 { --x; next} { print; }' < $< |\
	sort -k 14,14 -k 16,16n |\
	$(CMD_FARM) \
		--split-at-column=14 \
		--output-header $(CLUSTER_OPTIONS) \
		--renumber="%06i" \
		--renumber-column=":id" \
		--log=$@.log \
		--max-files=60 \
		--subdirs \
	"python $(DIR_SCRIPTS_GENEPREDICTION)blat2assembly.py \
		$(PARAM_TRANSCRIPTS_OPTIONS) \
		--genome=genome \
		--mali-output-format=fasta \
		$${transcripts_extra_options} \
		--log=$@.log \
		--output-filename-pattern=%DIR%$@.%s \
	" > $@
	$(EPILOG)
else
%.transcripts: %.filter
	$(PRELOG)
	@-ln -s $< $*.transcripts
	@-ln -s $< $*.transcripts.transcripts
	$(EPILOG)
endif

##################################################################
##################################################################
##################################################################
## Import results from assembly stage
##################################################################
%_transcripts.import: %.transcripts
	$(PRELOG)
	@perl -p -i -e "s/\tread\b/\tread_id/" < $< |\
	csv2db.py --map id:str -b sqlite --index=id --index=read_id --table=$*_transcripts > $@
	@if test -e $<.coverage; then \
		csv2db.py --map id:str -b sqlite --index=id --table=$*_coverage < $<.coverage >> $@; \
	fi
	@if test -e $<.polyA; then \
		csv2db.py --map id:str -b sqlite --index=id --table=$*_polyA < $<.polyA >> $@;\
	fi
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Output file with aligned regions
## Note that nested transcripts are merged. There are too many
## hits to resolve nested transcripts efficiently.
##################################################################
%_aligned.gtf: %.$(PARAM_MAPPING_METHOD)
	$(PRELOG)
	@cat $< |\
	python $(DIR_SCRIPTS_GENEPREDICTION)blat2blat.py --log=$@.log --method=rename-query --unique --output-filename-map=$@.id2new |\
	sort -k 14,14 -k16,16n |\
	$(CMD_FARM) \
		--split-at-column=14 \
		--output-header \
		$(CLUSTER_OPTIONS) \
		--renumber="M%06i" \
		--renumber-column=":id" \
		--log=$@.log \
		--subdirs \
		--max-files=60 \
	"python $(DIR_SCRIPTS_GENEPREDICTION)blat2assembly.py \
		--method=locus \
		--threshold-merge-distance=0 \
		--threshold-merge-overlap=1 \
		--force-merge=1000 \
		--staggered=all \
		--log=$@.log \
		--genome=genome \
		--output-filename-pattern=%DIR%$@.%s" \
	> $@.new2locus
	@python $(DIR_SCRIPTS_GENEPREDICTION)blat2gff.py \
		--log=$@.log \
		--as-gtf \
	< $@.locus.psl > $@
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Convert to gtf output
##################################################################
%_filter.gtf: %.filter
	$(PRELOG)
	@python $(DIR_SCRIPTS_GENEPREDICTION)blat2gff.py \
		--as-gtf -v 0 \
	< $*.filter |\
	$(DIR_SCRIPTS_GENEPREDICTION)gff_sort genes > $@
	$(EPILOG)


##################################################################
##################################################################
##################################################################
## Write a dummy coverage file
##################################################################
%_filter.coverage: %.filter
	$(PRELOG)
	@awk 'BEGIN \
		{ print ("id\tcontig\tstart\tend\tsize\tnmatches\tncovered\tnval\tmin\tmax\tmean\tmedian\tstddev\tsum\tq1\tq3"); } \
		/psLayout/ { x = 4; next; } x > 0 { --x; next} \
		{ printf ("%s\t%s\t%i\t%i\t%i\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\n", \
			 $$10, $$14, $$16, $$17, $$11); } ' \
	< $< > $@
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Convert to gtf output
##################################################################
%.gtf: %.transcripts
	$(PRELOG)
	@python $(DIR_SCRIPTS_GENEPREDICTION)blat2gff.py \
		--as-gtf -v 0 \
		--filename-strand=$<.transcripts.psl.strand \
	< $<.transcripts.psl |\
	$(DIR_SCRIPTS_GENEPREDICTION)gff_sort genes > $@
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Collect reads without matches
##################################################################
%.unaligned: %.$(PARAM_MAPPING_METHOD)
	$(PRELOG)
	@cut -f 10 $*.$(PARAM_MAPPING_METHOD) | sort | uniq > $@.tmp1
	@grep ">" $*.fasta | perl -p -e "s/>//; s/ .*//;" > $@.tmp2
	@perl $(DIR_SCRIPTS_TOOLS)set_rest.pl $@.tmp1 $@.tmp2 > $@
	@rm -f $@.tmp*
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Compute summary statistics of the matching and assembly steps
##################################################################
%.summary:
	@printf "######## summary for $* #########################\n"; \
	nreads=`grep -c "^>" $*.fasta`; \
	nbases=`awk '{a+=$$4;} END {printf("%i\n", a);}'  < $*.idx`;\
	naligned=`cut -f 10 $*.$(PARAM_MAPPING_METHOD) | sort | uniq | wc -l`;\
	nfiltered=`cut -f 10 $*.filter | sort | uniq | wc -l`; \
	printf "input: number of reads:\t%i\n" $${nreads} ; \
	printf "input: number of bases:\t%i\n" $${nbases} ; \
	printf "output: number of alignments:\t%i\n" `wc -l < $*.$(PARAM_MAPPING_METHOD)` ;\
	printf "output: number of aligned reads:\t%i\t%i%%\n" $${naligned} $$((100 * $${naligned} / $${nreads} )); \
	printf "output: number of filtered reads:\t%i\t%i%%\t(%i%%)\n" $${nfiltered} $$((100 * $${nfiltered} / $${nreads} )) $$((100 * $${nfiltered} / $${naligned} ))
	@if test -e  $*.transcripts.sbjct_coverage; then \
		python $(DIR_SCRIPTS_TOOLS)csv_cut.py ncovered nval < $*.transcripts.sbjct_coverage |\
		python $(DIR_SCRIPTS_TOOLS)data2stats.py |\
		awk '/sum/ { printf( "total sbjct coverage: \t%5.2f\n", 100*$$2/$$3) }'; \
		python $(DIR_SCRIPTS_TOOLS)csv_cut.py ncovered nval < $*.transcripts.sbjct_coverage |\
		awk '/nval/ {print; next;} {printf("%f\n", $$1/$$2);}' |\
		python $(DIR_SCRIPTS_TOOLS)data2stats.py |\
		awk '/mean/ { printf( "output: mean sbjct coverage: \t%5.2f\n", 100*$$2) } \
		    /median/ { printf( "output: median sbjct coverage: \t%5.2f\n", 100*$$2) }'; \
	fi
	@if test -e  $*.transcripts.coverage; then \
		python $(DIR_SCRIPTS_TOOLS)csv_cut.py mean median < $*.transcripts.coverage |\
		python $(DIR_SCRIPTS_TOOLS)data2stats.py |\
		awk '/category/ { next; } \
			/mean/ { printf( "output: mean mean/median coverage: \t%5.2f\t%5.2f\n", $$2, $$3) } \
			/median/ { printf( "output: median mean/median coverage: \t%5.2f\t%5.2f\n", $$2, $$3) }'; \
	fi
	@if test -e $*.filter.log; then \
		printf "filtering:\n"; \
		tail -n 7 $*.filter.log; \
	fi
	@if test -e $*.transcripts.log; then \
		printf "assembly:\n"; \
		tail -n 3 $*.transcripts.log; \
	fi

##################################################################
##################################################################
##################################################################
## Compute summary table
##################################################################
summary.table:
	$(PRELOG)
	@printf "set\treads\tbases\tnmatches\tnaligned\tpaligned\tnfiltered\tpfiltered1\tpfiltered2\tnassembled\tpassembled\tntranscripts\tscovsum\tscov\tscovmed\tcovavgavg\tcovavgmed\tcovmedavg\tcovmedmed\tmeansize\tcov\n" > $@
	@for x in $(INPUT); do \
		$(CMD_MSG2) "processing $${x}"; \
		printf "%s" $${x} >> $@;\
		let nreads=`grep -c "^>" $${x}.fasta`; \
		let nbases=`awk '{a+=$$4;} END {printf("%i\n", a);}'  < $${x}.idx`;\
		let naligned=`cut -f 10 $${x}.$(PARAM_MAPPING_METHOD) | sort | uniq | wc -l`;\
		let nfiltered=`cut -f 10 $${x}.filter | sort | uniq | wc -l`; \
		let nalignments=`wc -l < $${x}.$(PARAM_MAPPING_METHOD)` ;\
		let nduplicates=`wc -l < $${x}.transcripts.duplicates`-1 ;\
		let ntranscripts=`grep -c ">" < $${x}.transcripts.transcripts.psl.fasta`;\
		printf "\t%i\t%i\t%i\t%i\t%i\t%i\t%i\t%i\t%i\t%i\t%i" $${nreads} $${nbases} $${nalignments} \
			$${naligned} $$((100 * $${naligned} / $${nreads} )) \
			$${nfiltered} $$((100 * $${nfiltered} / $${nreads} )) \
			$$((100 * $${nfiltered} / $${naligned} )) \
			$$(($${nfiltered} - $${nduplicates})) \
			$$((100 * ($${nfiltered} - $${nduplicates}) / $${nreads} )) \
			$${ntranscripts} >> $@ ;\
		if test -e  $${x}.transcripts.sbjct_coverage; then \
			python $(DIR_SCRIPTS_TOOLS)csv_cut.py ncovered nval < $${x}.transcripts.sbjct_coverage |\
			python $(DIR_SCRIPTS_TOOLS)data2stats.py |\
			awk '/sum/ { printf( "\t%5.2f", 100*$$2/$$3) }' >> $@; \
			python $(DIR_SCRIPTS_TOOLS)csv_cut.py ncovered nval < $${x}.transcripts.sbjct_coverage |\
			awk '/nval/ {print; next;} {printf("%f", $$1/$$2);}' |\
			python $(DIR_SCRIPTS_TOOLS)data2stats.py |\
			awk '/mean/ { mean=100*$$2; } /median/ {median=100*$$2; } \
			     END { printf(\t%5.2f\t%5.2f",mean,median);}' >> $@;\
		else \
			printf "\tna\tna\tna" >> $@ ;\
		fi;\
		if test -e  $${x}.transcripts.coverage; then \
			python $(DIR_SCRIPTS_TOOLS)csv_cut.py mean median ncovered < $${x}.transcripts.coverage |\
			python $(DIR_SCRIPTS_TOOLS)data2stats.py |\
			awk '/category/ { next; } \
				/mean/ { meanmean=$$2; meanmedian=$$3; meanncovered=$$4} \
				/median/ { medianmean=$$2; medianmedian=$$3; medianncovered=$$4 } \
			     END { printf("\t%5.2f\t%5.2f\t%5.2f\t%5.2f", meanmean, meanmedian, medianmean, medianmedian, meanncovered ); }' >> $@; \
			python $(DIR_SCRIPTS_TOOLS)csv_cut.py -v 0 ncovered mean < $${x}.transcripts.coverage |\
				awk '/category/ { next; } \
				 	{ n += $$1; t += $$1 * $$2; } \
				END {printf("\t%5.2f", t / n); }' >> $@; \
			else \
				printf "\tna\tna\tna\tna\tna\tna" >> $@; \
			fi; \
		printf "\n" >> $@; \
	done
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Compute matching quality of reads before filtering
##################################################################
%.alignstats: %.$(PARAM_MAPPING_METHOD)
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) \
	python $(DIR_SCRIPTS_GENEPREDICTION)psl2table.py \
		--log=$@.log \
		--method=match \
		--without-match \
	< $< > $@
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Import matching quality of reads before filtering
##################################################################
%_alignstats.import: %.alignstats
	$(PRELOG)
	@perl -p -e "s/qName/read_id/" < $< |\
	csv2db.py --map gene_id:str -b sqlite --index=read_id --table=$*_alignstats > $@
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Compute matching quality of reads after filtering
##################################################################
%.filterstats: %.filter
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) \
	python $(DIR_SCRIPTS_GENEPREDICTION)psl2table.py \
		--log=$@.log \
		--method=match \
		--without-match \
	< $< > $@
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Import matching quality of reads after filtering
##################################################################
%_filterstats.import: %.filterstats
	$(PRELOG)
	@perl -p -e "s/qName/read_id/" < $< |\
	csv2db.py --map gene_id:str -b sqlite --index=read_id --table=$*_filterstats > $@
	$(EPILOG)


##################################################################
##################################################################
##################################################################
## Compute wiggle track of read depth after filtering
## There is no wigToBigWig on 32bit, hence use server
##################################################################
%_filter.bigwig: %.filter
	$(PRELOG)
	@$(CMD_SERVER_SUBMIT) -v mem_free=4000M \
	python $(DIR_SCRIPTS_GENEPREDICTION)blat2wiggle.py \
		--log=$@.log \
		--genome=genome \
		--bigwig-filename=$@ \
	< $< >> $@.log
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Compute wiggle track of read depth after filtering
## There is no wigToBigWig on 32bit, hence use server
##################################################################
%_filter.bedgraph.gz: %.filter
	$(PRELOG)
	@$(CMD_SERVER_SUBMIT) -v mem_free=4000M \
	python $(DIR_SCRIPTS_GENEPREDICTION)blat2wiggle.py \
		--log=$@.log \
		--genome=genome \
		--output-format=bedgraph \
	< $< | gzip > $@
	$(EPILOG)

########################################################
########################################################
########################################################
## count duplicates within and between sets
########################################################
ifneq ($(wildcard all.transcripts.duplicates),)
duplicates.png: all.transcripts
	$(PRELOG)
	@rm -f $@.tmp
	@for x in $(INPUT_NONDERIVED); do \
		awk -v set=$${x} '{printf("%s\t%s\n", $$1, set);}' < $${x}.idx; done | grep -v -e "all" > $@.tmp
	@python $(DIR_SCRIPTS_TOOLS)substitute_tokens.py \
		--apply=$@.tmp --column=1 < all.transcripts.duplicates |\
	python $(DIR_SCRIPTS_TOOLS)substitute_tokens.py \
		--apply=$@.tmp --column=2 |\
	awk '!/mem/ {if ($$1 < $$2) { printf("%s-%s\n", $$1,$$2); } else { printf("%s-%s\n",$$2,$$1); } }' | sort | count |\
	pe "s/-/\t/" | g2m > $@.table
	m2p --hardcopy=$@ --title="Duplicates between sets" --labels="set,set" < $@.table
	@rm -f $@.tmp
	$(EPILOG)
else
duplicates.png:
endif

########################################################
########################################################
########################################################
## ucsc tracks file
########################################################
%.ucsc_tracks:
	$(PRELOG)
	@outfile=~/public_html/ucsc_tracks/$*_reads.psl; \
	rm -f $${outfile}; \
	printf 'track name="%s" description="%s" visibility="full"\n' $${d} $${d} >> $${outfile}; \
	awk '$$14 != "chrMT" && $$14 != "chrUn"' < $*.filter >> $${outfile}; \
	rm -f $${outfile}.gz ;\
	gzip $${outfile}
	@echo "paste the following URL: http://wwwfgu.anat.ox.ac.uk/~$(USER)/ucsc_tracks/$*_reads.psl.gz"
	$(EPILOG)

########################################################
########################################################
########################################################
## ucsc tracks file for filtered reads: individual set
########################################################
%.ucsc-track-filtered:
	$(PRELOG)
	@outfile=~/public_html/ucsc_tracks/$(PARAM_PROJECT_NAME)_filtered_$*.psl; \
	rm -f $${outfile}; \
	printf 'track name="%s" description="%s" visibility="full"\n' $${d} $${d} >> $${outfile}; \
	awk '$$14 != "chrMT" && $$14 != "chrUn"' < $*.filter >> $${outfile}; \
	rm -f $${outfile}.gz ;\
	gzip $${outfile}
	@echo "paste the following URL: http://wwwfgu.anat.ox.ac.uk/~$(USER)/ucsc_tracks/$(PARAM_PROJECT_NAME)_filtered_$*.psl.gz"
	$(EPILOG)

########################################################
########################################################
########################################################
## ucsc tracks file for mapped reads: individual set
########################################################
%.ucsc-track-mapped:
	$(PRELOG)
	@outfile=~/public_html/ucsc_tracks/$(PARAM_PROJECT_NAME)_mapped_$*.psl; \
	rm -f $${outfile}; \
	printf 'track name="%s" description="%s" visibility="full"\n' $${d} $${d} >> $${outfile}; \
	awk '$$14 != "chrMT" && $$14 != "chrUn"' < $*.$(PARAM_MAPPING_METHOD) >> $${outfile}; \
	rm -f $${outfile}.gz ;\
	gzip $${outfile}
	@echo "paste the following URL: http://wwwfgu.anat.ox.ac.uk/~$(USER)/ucsc_tracks/$(PARAM_PROJECT_NAME)_mapped_$*.psl.gz"
	$(EPILOG)

########################################################
########################################################
########################################################
## ucsc tracks file for mapped reads: individual set
########################################################
%.ucsc-track-assembled:
	$(PRELOG)
	@outfile=~/public_html/ucsc_tracks/$(PARAM_PROJECT_NAME)_assembled_$*.psl; \
	rm -f $${outfile}; \
	printf 'track name="%s" description="%s" visibility="full"\n' $${d} $${d} >> $${outfile}; \
	awk '$$14 != "chrMT" && $$14 != "chrUn"' < $*.transcripts.transcripts >> $${outfile}; \
	rm -f $${outfile}.gz ;\
	gzip $${outfile}
	@echo "paste the following URL: http://wwwfgu.anat.ox.ac.uk/~$(USER)/ucsc_tracks/$(PARAM_PROJECT_NAME)_assembled_$*.psl.gz"
	$(EPILOG)


########################################################
########################################################
########################################################
## ucsc tracks file: one file with all mapped tracks
########################################################
ucsc-tracks-filtered: UCSC_FILES=$(FILTERED)
ucsc-tracks-mapped: UCSC_FILES=$(MAPPED)

ucsc-tracks-%:
	$(PRELOG)
	@outfile=~/public_html/ucsc_tracks/$(PARAM_PROJECT_NAME)_$*_all.psl; \
	rm -f $${outfile}; \
	for x in $(UCSC_FILES); do \
		printf 'track name="%s" description="%s" visibility="full"\n' $${x} $${x} >> $${outfile}; \
		awk '$$14 != "chrMT"' < $${x} >> $${outfile}; \
	done ; \
	rm -f $${outfile}.gz ;\
	gzip $${outfile}
	@echo "paste the following URL: http://wwwfgu.anat.ox.ac.uk/~$(USER)/ucsc_tracks/$(PARAM_PROJECT_NAME)_$*_all.psl.gz"
	$(EPILOG)

########################################################
########################################################
########################################################
# ucsc tracks file: one file with all assembled sets
########################################################
ucsc-tracks-assembled:
	$(PRELOG)
	@outfile=~/public_html/ucsc_tracks/$(PARAM_PROJECT_NAME)_assembled_all.gtf; \
	rm -f $${outfile}; \
	for x in $(GTFS); do \
		printf 'track name="%s" description="%s" visibility="full"\n' $${x} $${x} >> $${outfile}; \
		python $(DIR_SCRIPTS_GENEPREDICTION)gff2gff.py --sanitize=ucsc -v 0 < $${x} |\
		awk '$$1 != "chrMT"' \
		>> $${outfile}; \
	done; \
	rm -f $${outfile}.gz ;\
	gzip $${outfile}
	@echo "paste the following URL: http://wwwfgu.anat.ox.ac.uk/~$(USER)/ucsc_tracks/$(PARAM_PROJECT_NAME)_assembled_all.gtf.gz"
	$(EPILOG)

########################################################
########################################################
########################################################
# ucsc tracks file: one file with all assembled sets
########################################################
ucsc-bigwig:
	$(PRELOG)
	@echo "to view all, paste the following into the UCSC annotations box:"
	@for f in *.bigwig; do \
		rm -f ~/public_html/ucsc_tracks/$(PARAM_PROJECT_NAME)_$${f}; \
		cp $${f} ~/public_html/ucsc_tracks/$(PARAM_PROJECT_NAME)_$${f}; \
		printf 'track type=bigWig name="%s" description="%s" dataUrl=http://wwwfgu.anat.ox.ac.uk/~$(USER)/ucsc_tracks/$(PARAM_PROJECT_NAME)_%s\n' $${f} $${f} $${f}; \
	done
	$(EPILOG)

########################################################
########################################################
########################################################
# ucsc tracks file: one file with all assembled sets
########################################################
ucsc-bedgraph:
	$(PRELOG)
	@outfile=~/public_html/ucsc_tracks/$(PARAM_PROJECT_NAME).bedgraph.gz; \
	rm -f $${outfile}; \
	for f in *.bedgraph.gz; do \
		printf "track type=bedGraph name=\"$${f}\" visibility=dense\n" | gzip >> $${outfile}; \
		cat $${f} >> $${outfile} ; \
	done
	@echo "paste the following URL: http://wwwfgu.anat.ox.ac.uk/~$(USER)/ucsc_tracks/$(PARAM_PROJECT_NAME).bedgraph.gz"
	$(EPILOG)

########################################################
########################################################
########################################################
## view a set of transcripts on the ucsc browser. Upload custom tracks beforehand
## make sure that ids are correct and alphanumeric (000001 instead of 1).
## set the variable PARAM_VIEW_SET
########################################################
%.view: %
	@python $(DIR_SCRIPTS_GENEPREDICTION)gtf2gtf.py \
		--filter=gene \
		--apply=$< \
	< $(PARAM_VIEW_SET).gtf |\
	python $(DIR_SCRIPTS_GENEPREDICTION)gff2view.py \
		--genome-file=$(PARAM_FILENAME_GENOME) \
		--ucsc-assembly=$(PARAM_VIEW_UCSC_ASSEMBLY) \
		--is-gtf \
		-

########################################################
########################################################
########################################################
## Various plotting and table routines
## see PipeBook
########################################################
COMBINE_PLOTS=python $(DIR_SCRIPTS_TOOLS)combine_tables.py $@.tmp_* | python $(DIR_SCRIPTS_TOOLS)plot_histogram.py $(PLOT_OPTIONS) --hardcopy=$@; rm -f $@.tmp*

read_length: PLOT_OPTIONS=

read_length.png:
	$(PRELOG)
	@for x in $(INPUT); do \
		python $(DIR_SCRIPTS_TOOLS)csv_cut.py id length < $${x}.readstats |\
		grep -v "total" |\
		python $(DIR_SCRIPTS_TOOLS)data2histogram.py --headers=$${x} --column=2 --normalize > $@.tmp_$${x}; \
	done; \
	python $(DIR_SCRIPTS_TOOLS)combine_tables.py $@.tmp_* |\
	python $(DIR_SCRIPTS_TOOLS)plot_histogram.py --hardcopy=$@ --title="Distribution of read length" --xtitle="read length / bases" --ytitle="relative frequency" $(PLOT_OPTIONS)
	@rm -f $@.tmp*
	$(EPILOG)

pgc.png:
	$(PRELOG)
	@for x in $(INPUT); do \
		python $(DIR_SCRIPTS_TOOLS)csv_cut.py id pGC < $${x}.readstats |\
		grep -v "total" |\
		python $(DIR_SCRIPTS_TOOLS)data2histogram.py --headers=$${x} --column=2 --bin-size=0.01 --normalize > $@.tmp_$${x}; \
	done; \
	python $(DIR_SCRIPTS_TOOLS)combine_tables.py $@.tmp_* |\
	python $(DIR_SCRIPTS_TOOLS)plot_histogram.py --hardcopy=$@ --title="Distribution of G+C in reads" --xtitle="GC" --ytitle="relative frequency"
	@rm -f $@.tmp*
	$(EPILOG)

read_length_eliminated.png:
	$(PRELOG)
	@for x in $(INPUT); do \
		python $(DIR_SCRIPTS_TOOLS)csv_cut.py id length < $${x}.readstats |\
		grep -v "total" |\
		python $(DIR_SCRIPTS_TOOLS)filter_tokens.py --apply=<(cut -f 1 $${x}.filter.empty) --column=1 |\
		python $(DIR_SCRIPTS_TOOLS)data2histogram.py --headers=$${x} --column=2 --normalize > $@.tmp_$${x}; \
	done; \
	python $(DIR_SCRIPTS_TOOLS)combine_tables.py $@.tmp_* |\
	python $(DIR_SCRIPTS_TOOLS)plot_histogram.py --hardcopy=$@ --title="Distribution of length of eliminated reads" --xtitle="read length / bases" --ytitle="relative frequency"
	@rm -f $@.tmp*
	$(EPILOG)

read_length_accepted.png:
	$(PRELOG)
	@for x in $(INPUT); do \
		python $(DIR_SCRIPTS_TOOLS)csv_cut.py id length < $${x}.readstats |\
		grep -v "total" |\
		python $(DIR_SCRIPTS_TOOLS)filter_tokens.py --apply=<(cut -f 1 $${x}.filter.empty) --invert-match --column=1 |\
		python $(DIR_SCRIPTS_TOOLS)data2histogram.py --headers=$${x} --column=2 --normalize > $@.tmp_$${x}; \
	done; \
	python $(DIR_SCRIPTS_TOOLS)combine_tables.py $@.tmp_* |\
	python $(DIR_SCRIPTS_TOOLS)plot_histogram.py --hardcopy=$@ --title="Distribution of length of accepted reads" --xtitle="read length / bases" --ytitle="relative frequency"
	@rm -f $@.tmp*
	$(EPILOG)


stats_%.table:
	$(PRELOG)
	@for c in pid qCov; do \
		for x in $(INPUT); do \
			csv_cut $${c} < $${x}.$*stats | d2s --headers=$${x} > $@.tmp_stats_$${x}; \
			csv_cut $${c} < $${x}.$*stats | d2h --min-value=0 --bin-size=1 --headers=$${x} > $@.tmp_hist_$${x}; \
		done; \
		python $(DIR_SCRIPTS_TOOLS)combine_tables.py $@.tmp_stats* > $@.$${c}.stats; \
		python $(DIR_SCRIPTS_TOOLS)combine_histograms.py $@.tmp_hist* > $@.$${c}.hist; \
		h2p --normalize --cumulate --hardcopy=$@.$${c}.hist.png --xrange=50,100 \
			--as-lines \
			--ytitle="cumulative relative frequency" --legend-location="center" \
			< $@.$${c}.hist > $@; \
	done
	@rm -f $@.tmp*
	$(EPILOG)

###########################################################################
###########################################################################
###########################################################################
## plot of median coverage of transcripts
###########################################################################
coverage_median.png: PLOT_OPTIONS=--logscale=x --title="Median coverage of transcripts" --xtitle="mean coverage" --legend-location="center right" --ytitle="relative frequency"
coverage_median.png:
	$(PRELOG)
	@for x in $(INPUT); do \
		python $(DIR_SCRIPTS_TOOLS)csv_cut.py median < $${x}.transcripts.coverage |\
		python $(DIR_SCRIPTS_TOOLS)data2histogram.py --headers=$${x} --column=1 --bin-size=1 --normalize > $@.tmp_$${x}; \
	done; \
	$(COMBINE_PLOTS)
	$(EPILOG)

###########################################################################
###########################################################################
###########################################################################
## plot of mean coverage of transcripts
###########################################################################
coverage_mean.png: PLOT_OPTIONS=--logscale=x --title="Mean coverage of transcripts" --xtitle="mean coverage" --legend-location="center right" --ytitle="relative frequency"
coverage_mean.png:
	$(PRELOG)
	@for x in $(INPUT); do \
		python $(DIR_SCRIPTS_TOOLS)csv_cut.py mean < $${x}.transcripts.coverage |\
		python $(DIR_SCRIPTS_TOOLS)data2histogram.py --headers=$${x} --column=1 --bin-size=1 --normalize > $@.tmp_$${x}; \
	done; \
	$(COMBINE_PLOTS)
	$(EPILOG)

###########################################################################
###########################################################################
###########################################################################
## plot of alignment positions
###########################################################################
missing_residues.plots: PLOT_OPTIONS=--title="Histogram of unaligned residues at termini of accepted reads in set $${x}" \
	--xtitle="unaligned / bp" --legend-location="center right" --ytitle="frequency" --legend="residues,5end,3end"
missing_residues.plots:
	$(PRELOG)
	@for x in $(INPUT); do \
		awk 'NR > 5 {printf("%s\t%s\n", ($$12 >= 0) ? $$12 : "na", ($$11-$$13 >= 0) ? $$11-$$13 : "na" ); }' < $${x}.filter > $@.tmp; \
		cat $@.tmp | python $(DIR_SCRIPTS_TOOLS)data2histogram.py |\
		python $(DIR_SCRIPTS_TOOLS)plot_histogram.py $(PLOT_OPTIONS) --hardcopy=$@_$${x}.png --logscale=xy >> $@; \
		cat $@.tmp | python $(DIR_SCRIPTS_TOOLS)data2histogram.py |\
		python $(DIR_SCRIPTS_TOOLS)plot_histogram.py $(PLOT_OPTIONS) --cumulate --hardcopy=$@_$${x}_cumul.png --logscale=xy >> $@; \
		cat $@.tmp | python $(DIR_SCRIPTS_TOOLS)data2histogram.py |\
		python $(DIR_SCRIPTS_TOOLS)plot_histogram.py $(PLOT_OPTIONS) --cumulate --normalize --hardcopy=$@_$${x}_relcumul.png >> $@; \
	done
	@rm -f $@.tmp
	$(EPILOG)

##################################################################
##################################################################
##################################################################
## Position of reads
##################################################################
readpos.plots: PLOT_OPTIONS=--log=$@ --ytitle="frequency" --legend-location="lower right" --as-lines

readpos.plots:
	$(PRELOG)
	@for x in $(INPUT); do \
		python $(DIR_SCRIPTS_GENEPREDICTION)analyze_readpositions.py \
			--log=$@ \
			--output-filename-pattern=$@_$${x}.%s \
			< $${x}.readpos |\
		h2p $(PLOT_OPTIONS) \
			--title="residue coverage of reference gene models with reads in set $${x}" \
			--hardcopy=$@.$${x}.png; \
		h2p $(PLOT_OPTIONS) \
			--title="residue coverage of reference gene models with reads in set $${x} - 5prime end" \
			--hardcopy=$@.$${x}_5prime.png \
		< $@_$${x}.reads5; \
		h2p $(PLOT_OPTIONS) \
			--title="residue coverage of reference gene models with reads in set $${x} - 3prime end" \
			--hardcopy=$@.$${x}_3prime.png \
		< $@_$${x}.reads3; \
	done
	$(EPILOG)



##################################################################
##################################################################
##################################################################
## Distribution of number of matches per query
##################################################################
degeneracy.png:
	@printf "data\t" > $@.stats
	d2s --flat --write-header >> $@.stats
	@for x in $(INPUT); do \
		printf "$${x}\n" > $@.tmp; \
		cut -f 10 $${x}.$(PARAM_MAPPING_METHOD) | uniq -c | awk '{printf("%i\n",$$1);}' >> $@.tmp; \
		d2s --flat --skip-header < $@.tmp >> $@.stats; \
		d2h < $@.tmp > $@.tmp_$${x}; \
	done
	$(COMBINE_PLOTS)



###########################################################################
include $(DIR_SCRIPTS_GENEPREDICTION)/makefiles/Makefile.common

