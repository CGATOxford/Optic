################################################################################
#   Gene prediction pipeline 
#
#   $Id: Makefile.common 2781 2009-09-10 11:33:14Z andreas $
#
#   Copyright (C) 2004 Andreas Heger
#
#   This program is free software; you can redistribute it and/or
#   modify it under the terms of the GNU General Public License
#   as published by the Free Software Foundation; either version 2
#   of the License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
#################################################################################

SHELL=/bin/bash -O expand_aliases 
LOG=log

################################################
## Section parameters: start
################################################

################################################
## Directories

## Directory where gene prediction scripts can be found
DIR_SCRIPTS?=/ifs/devel/cgat/
## deprecated, use DIR_SCRIPTS from now on
DIR_SCRIPTS_GENEPREDICTION?=$(DIR_SCRIPTS)
## deprecated, use DIR_SCRIPTS from now on
DIR_SCRIPTS_TOOLS?=$(DIR_SCRIPTS)
## Temporary directory to us
DIR_TMP?=/net/cpp-data/scratch/andreas/tmp/
## The root directory for this project
DIR_ROOT?=$(CURDIR)/

################################################
################################################
## Options for queue control
################################################

## priority on the cluster
PARAM_PRIORITY?=-10

## queue to use
PARAM_QUEUE?=medium_jobs.q

PARAM_QUEUE_SERVER?=server_jobs.q
PARAM_QUEUE_LOCAL?=local_jobs.q

## number of jobs to submit to the queue in parallel
PARAM_NUM_JOBS?=100

## .bashrc to use for running jobs on the cluster
PARAM_BASHRC?=~/.bashrc_cluster

## additional cluster options, for example
## -l mem=3000
PARAM_CLUSTER_OPTIONS?=

################################################
################################################
## General options for postgres
## Note: PARAM_PSQL_SCHEMA is usually defined
## in calling Makefile.
################################################
## database
PARAM_PSQL_DATABASE?=postgres
## host
PARAM_PSQL_HOST?=db
## user
PARAM_PSQL_USER?=andreas

################################################
## Section parameters: end
################################################

#########################################################################
## commonly used variables
## Postgres
PSQL_CONNECTION=psql -h $(PARAM_PSQL_HOST) -d $(PARAM_PSQL_DATABASE) $(PARAM_PSQL_USER) -c
PSQL_CONNECTION_BATCH=psql -h $(PARAM_PSQL_HOST) -d $(PARAM_PSQL_DATABASE) $(PARAM_PSQL_USER) -f
PSQL_CONNECTION_OPTIONS=-t -A -F"	" 
PSQL_SELECT=psql -h $(PARAM_PSQL_HOST) -d $(PARAM_PSQL_DATABASE) $(PARAM_PSQL_USER) -t -A -F"	" -c
CMD_TABLE_PREFIX=`echo $* | perl -p -e "s/\./_/g"`

## Options for python scripts
PSQL_PYTHON_OPTIONS=--connection=$(PARAM_PSQL_HOST):$(PARAM_PSQL_DATABASE)

#########################################################################
## empty target
nop:

#########################################################################
## output help - a list of primary targets, parameters and rules defined
## in the makefile.
help:
	@python $(DIR_SCRIPTS_GENEPREDICTION)cgat_make2help.py

#########################################################################
## Setting up logfiles
create-log-hook: create-log-pre-hook

create-log-pre-hook:
	@echo "#################`date`#############################" $(TOLOG)
	@echo "# Gene prediction pipeline of the Ponting Group, MRC" $(TOLOG)
	@echo "# This is Makefile version $(VERSION)" $(TOLOG)
	@echo "# Working directory: $(CURDIR)" $(TOLOG)
	@echo "# Parameters" $(TOLOG)
	@$(MAKE) -p nop | awk '/^# Variables/ { keep = 1} /^# Directories/ { keep = 0; } \
	/^PARAM_/ {if (keep) {print;}} \
	/^SHELL/ {if (keep) {print;}} \
	/^INPUT_/ {if (keep) {print;}} \
	/^DIR_/ {if (keep) {print;}}' | sort $(TOLOG)
	@echo "#################`date`#############################" $(TOLOG)

## create a log file
## This command will a list of defined parameters to the $(LOG) file.
create-log: create-log-pre-hook create-log-hook

#########################################################################
## Commands for writing logfiles
CMD_LOG2?=echo -e >> $(LOG) "\# `date`:"
CMD_LOG?=@$(CMD_LOG2)

CMD_MSG2?=echo -e "\# `date`:"
CMD_MSG?=@$(CMD_MSG2)

TOLOG?=>> $(LOG)
LOG_HR1?=@echo "\#==============================================================================================" $(TOLOG)
LOG_HR2?=@echo "\#----------------------------------------------------------------------------------------------" $(TOLOG)
LOG_HR2v?=echo "\#----------------------------------------------------------------------------------------------" $(TOLOG)

TO_NULL?=>& /dev/null

#########################################################################
## message to echo at start of task
PRELOG?=$(CMD_LOG) "$@ started."

## message to echo at end of task
EPILOG?=$(CMD_LOG) "$@ completed."

#########################################################################
CMD_CLOSE?=@echo "\# job finished at: `date`" >> $@

#########################################################################
## record benchmarking information
PYTHON_BENCHMARK_OPTIONS?=--timeit=$(DIR_ROOT)timeit.log --timeit-name=$@ 
PYTHON_OPTIONS?=$(PYTHON_BENCHMARK_OPTIONS)
CMD_BENCHMARK=python $(DIR_SCRIPTS)run.py $(PYTHON_OPTIONS)

#########################################################################
## prefix for commands to be executed on cluster nodes
## set BASH_ENV in order to ensure that bashrc is executed,
## so that a cluster specific environment can be set.
CMD_REMOTE_SUBMIT?=qrsh \
	-cwd \
	-now n \
	-V \
	-p $(PARAM_PRIORITY) \
	-q $(PARAM_QUEUE) \
	-N $(PARAM_PROJECT_NAME)_`echo $@ | tr -d :` 

#########################################################################
## prefix for commands to be executed on server nodes. These are high memory,
## multiple CPU machines.
## set BASH_ENV in order to ensure that bashrc is executed,
## so that a cluster specific environment can be set.
CMD_SERVER_SUBMIT?=qrsh \
	-cwd \
	-now n \
	-v BASH_ENV=$(PARAM_BASHRC) \
	-p $(PARAM_PRIORITY) \
	-q $(PARAM_QUEUE_SERVER) \
	-N $(PARAM_PROJECT_NAME)_`echo $@ | tr -d :` 

#########################################################################
## prefix for commands to be executed on the local node. Use these jobs 
## that require a lot of local processing of files like zipping and sorting.
CMD_LOCAL_SUBMIT?=qrsh \
	-cwd \
	-now n \
	-v BASH_ENV=$(PARAM_BASHRC) \
	-p $(PARAM_PRIORITY) \
	-q $(PARAM_QUEUE_LOCAL) \
	-N $(PARAM_PROJECT_NAME)_`echo $@ | tr -d :` 


#########################################################################
## cmd to execute a farm job
CMD_FARM?=farm.py --cluster-priority=$(PARAM_PRIORITY) \
		--cluster-queue=$(PARAM_QUEUE) \
		--cluster-num-jobs=$(PARAM_NUM_JOBS) \
		--cluster-options="$(PARAM_CLUSTER_OPTIONS)"

#########################################################################
## create a subdirectory and create symbolic link to Makefile in parent directory.
%.dir:
	@-mkdir $@
	@ln -s ../Makefile $@/Makefile

#########################################################################
## check for requisites.
check-setup: check-setup-pre-hook check-setup-hook

check-setup-pre-hook:
	@echo "##############################################################"
	@echo -e "\nChecking prerequisites for $(PARAM_PROJECT_NAME)"
	@echo -e "in $(CURDIR)\n"
	@m=0; \
	for file in $(FILES_REQUISITES); do \
		if test ! -e $$file; then \
			echo "ERROR: failed to find file $$file"; let m=m+1; \
		else \
			echo "found: $$file"; \
		fi; \
	done; \
	if [[ $$m == 0 ]]; then \
		echo -e "\nAll files present - share and enjoy!"; \
	else \
		echo -e "\n$$m input files are missing."; \
	fi
	@echo "##############################################################"

check-setup-hook: check-setup-pre-hook

################################################################################################
## Create a map between internally used names and those used for export. Use either the variable
## PARAM_SRC_SCHEMAS or the file input.species.
################################################################################################
## Create a map between internally used names and those used for export. Use either the variable
## PARAM_SRC_SCHEMAS or the file input.species.
translation:
	$(PRELOG)
ifdef PARAM_SRC_SCHEMAS
	@rm -f $@
	@genomes=( $(PARAM_SRC_SCHEMAS) ); \
	names=( $(PARAM_SRC_NAMES) ); \
	for (( x = 0; x < $(PARAM_NUM_GENOMES); ++x )); do \
		printf "%s\t%s\n" $${genomes[$$x]} $${names[$$x]} >> $@; \
	done
else
	@awk '!/^#/ {printf("%s\t%s\n", $$1,$$1);}' < input.species > $@
endif
	$(EPILOG)

## command to do the translation
CMD_TRANSLATE=$(YT)substitute_tokens.py --apply=translation
CMD_TRANSLATE_BACK=$(YT)substitute_tokens.py --apply=translation --invert

################################################################################################
## Common processing commands
##
## Remove header and comments from a file
CMD_REMOVE_HEADER=sed '/^\#/d; 1,1d'

################################################################################################
## Common script commands:
ET=perl $(DIR_SCRIPTS_TOOLS)
EG=perl $(DIR_SCRIPTS_GENE_PREDICTION)
YT=python $(DIR_SCRIPTS_TOOLS)
YG=python $(DIR_SCRIPTS_GENE_PREDICTION)
