################################################################################
#   Gene prediction pipeline 
#
#   $Id: Makefile.orthology_pairwise 2815 2009-11-09 09:32:51Z andreas $
#
#   Copyright (C) 2004 Andreas Heger
#
#   This program is free software; you can redistribute it and/or
#   modify it under the terms of the GNU General Public License
#   as published by the Free Software Foundation; either version 2
#   of the License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
#################################################################################
SHELL=/bin/bash --login

LOG=log

################################################
## Section parameters: start
################################################
## genomes to use
PARAM_GENOME1?=
PARAM_GENOME2?=

## project name
PARAM_PROJECT_NAME?=geneprediction
PARAM_INPUT_FILES?=peptides1.fasta peptides2.fasta exons1.exons exons2.exons cds1.exons cds2.exons

PARAM_SEPARATOR?=|

## pattern to get species from identifier
PARAM_INPUT_GENOME?=^([^$(PARAM_SEPARATOR)]+)[^$(PARAM_SEPARATOR)]

################################################
## Step1: building alignments between peptides
## number of jobs
PARAM_STEP1_NUMJOBS?=100
## number of queries per blast job
PARAM_STEP1_CHUNKSIZE?=1000
PARAM_STEP1_REDUNDANCY_LEVEL?=0.9
PARAM_STEP1_BLASTP_OPTIONS?=-e 1e-5 -v 5000 -b 5000 -F F
PARAM_STEP1_BLASTP_PARSING?=--ends --table --len --noheader --log --bits
PARAM_STEP1_BLASTP_NUMFIELDS?=14

################################################
## Step2: building the input graph

## minimum minimum coverage (coverage of larger peptide)
PARAM_STEP2_MIN_MIN_COVERAGE?=0

## minimum maximum coverage (coverage of smaller peptide)
PARAM_STEP2_MIN_MAX_COVERAGE?=0.75

## minimum score to use (default: do not filter by score)
PARAM_STEP2_MIN_SCORE?=0.00

## minimum distance to use
PARAM_STEP2_MAX_DISTANCE?=0.80

## best hits per query to enter into pair graph.
PARAM_STEP2_NBESTHITS?=10

## quality of predictions to restrict analysis to
PARAM_RESTRICT_QUALITY=CG,SG,PG,RG,CP,SP,PP

## quality of predictions chosen as seeds for the analysis
PARAM_STEP2_QUALITY_SEEDS?=$(PARAM_RESTRICT_QUALITY)

################################################
## step2 options when using ks
##

## define this variable to use ks in step 2
PARAM_STEP2_USE_KS?=
## number of jobs
PARAM_STEP2_NUMJOBS?=100
## number of queries per blast job
PARAM_STEP2_CHUNKSIZE?=10000
## minimum length for kaks calculations.
PARAM_STEP2_MIN_LENGTH?=100
## maximum ks to accept 
PARAM_STEP2_MAX_KS?=5.0

################################################
## Step3: pairwise orthology assignment
## number of jobs
PARAM_STEP3_NUMJOBS?=100

################################################
# Step5: analyse orthology results
PARAM_STEP5_MAX_DUPLICATIONS?=20

################################################
## Step6: running kaks
## number of jobs
PARAM_STEP6_NUMJOBS?=100
## number of queries per blast job
PARAM_STEP6_CHUNKSIZE?=4000
## minimum length for kaks calculations.
PARAM_STEP6_MIN_LENGTH=100

################################################
## Step7: pairwise orthology assignment
## number of jobs
PARAM_STEP7_NUMJOBS?=100

################################################
## Step9: pairwise orthology assignment
## number of jobs
PARAM_STEP9_NUMJOBS?=100

## maximum distance for step9 (ks)
PARAM_STEP9_MAX_DISTANCE?=5.0

## define, if you want to map genes
## note: currently broken
PARAM_STEP9_MAP_GENES?=

################################################
PARAM_STEP10_MAX_DUPLICATIONS?=20

################################################
# Section parameters: end
################################################

FILES_REQUISITES?=$(PARAM_INPUT_FILES)

################################################
################################################
################################################
################################################
################################################
################################################
################################################
## command to use for submitting remote jobs

TARGETS=step1 step2 step3 step5 step6 step7 step9 step10 step11

all: $(TARGETS)

################################################
STEP1_PREVIOUS_LINKS=$(wildcard previous.links)
STEP1_PREVIOUS_SEQUENCES=$(wildcard previous.fasta)

STEP1_EFFECTIVE_LENGTH=`grep -c ">" $(STEP1_PREVIOUS_SEQUENCES)`

## step1: setup blast and run it. This can be either
## de novo or starting from a previous run. Targets step1.prepare
## and step1.run differ accordingly.
step1: step1.prepare step1.run step1.finish 
	@touch $@
	$(EPILOG)	

##################################################################
## Begin of alternative step1 processing
ifneq ($(STEP1_PREVIOUS_SEQUENCES), )
## split input file into new and old and setup two blast jobs
## (new against all, all against new)
step1.prepare: step1.queries.fasta 
	$(PRELOG)
	@python $(DIR_SCRIPTS_GENEPREDICTION)optic/update_blast.py \
	$(PYTHON_OPTIONS) \
	--old-query-sequences=$(STEP1_PREVIOUS_SEQUENCES) \
	--new-query-sequences=step1.queries.fasta \
	--write-fasta --fasta-pattern=step1.%s.fasta \
	--output-pattern=step1.%s.update > $@
	@python $(DIR_SCRIPTS_GENEPREDICTION)gpipe/setup.py -f -m blast \
		-p $(PARAM_PROJECT_NAME)_blast_all_vs_new \
		-d step1.all_vs_new.dir \
		-o $(DIR_ROOT) \
		-i ../../data/Makefile.inc \
		PARAM_BLASTP_NUMJOBS=$(PARAM_STEP1_NUMJOBS) \
		PARAM_BLASTP_CHUNKSIZE=$(PARAM_STEP1_CHUNKSIZE) \
		PARAM_BLASTP_NUMFIELDS="$(PARAM_STEP1_BLASTP_NUMFIELDS)" \
		PARAM_BLASTP_PARSING="$(PARAM_STEP1_BLASTP_PARSING)" \
		PARAM_BLASTP_OPTIONS="$(PARAM_STEP1_BLASTP_OPTIONS) -z $(STEP1_EFFECTIVE_LENGTH)" \
		DIR_TMP=./ \
		PARAM_PRIORITY=$(PARAM_PRIORITY) >> $@
	@-ln -s ../step1.queries.fasta   step1.all_vs_new.dir/queries.fasta
	@-ln -s ../step1.query_new.fasta step1.all_vs_new.dir/sbjcts.fasta
	@python $(DIR_SCRIPTS_GENEPREDICTION)gpipe/setup.py -f -m blast \
		-p $(PARAM_PROJECT_NAME)_blast_new_vs_all \
		-d step1.new_vs_all.dir \
		-i ../../data/Makefile.inc \
		-o $(DIR_ROOT) \
		PARAM_BLASTP_NUMJOBS=$(PARAM_STEP1_NUMJOBS) \
		PARAM_BLASTP_CHUNKSIZE=$(PARAM_STEP1_CHUNKSIZE) \
		PARAM_BLASTP_NUMFIELDS="$(PARAM_STEP1_BLASTP_NUMFIELDS)" \
		PARAM_BLASTP_PARSING="$(PARAM_STEP1_BLASTP_PARSING)" \
		PARAM_BLASTP_OPTIONS="$(PARAM_STEP1_BLASTP_OPTIONS) -z $(STEP1_EFFECTIVE_LENGTH)" \
		DIR_TMP=./ \
		PARAM_PRIORITY=$(PARAM_PRIORITY) >> $@
	@-ln -s ../step1.query_new.fasta step1.new_vs_all.dir/queries.fasta
	@-ln -s ../step1.queries.fasta   step1.new_vs_all.dir/sbjcts.fasta
	$(EPILOG)

step1.run: step1.prepare
	$(PRELOG)
	@if test -e step1.new_vs_all.dir; then \
		$(CMD_BENCHMARK) $(MAKE) -C step1.new_vs_all.dir -k blast; \
	fi
	@if test -e step1.all_vs_new.dir; then \
		$(CMD_BENCHMARK) $(MAKE) -C step1.all_vs_new.dir -k blast; \
	fi
	@touch $@
	$(MAKE) step1.previous_links.gz
	$(EPILOG)

step1.previous_links.gz: step1.prepare
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) "gunzip < $(STEP1_PREVIOUS_LINKS) |\
	map_alignments -m step1.old2new.map.update -s -i -k -v 2 -r 10000 2>$@.log |\
	grep -v '#' |\
	sort -T $(DIR_TMP) -k1,1 -k3,3n -k2,2 -k4,10 |\
	uniq | gzip" \
	< /dev/null > $@
	$(EPILOG)

# 	@rm -rf step1.all_vs_new.dir
# 	@rm -rf step1.new_vs_all.dir
# 	@rm -f step1.previous_links.gz

step1.finish: step1.run 
	$(PRELOG)
	@-mkdir step1.dir
	@$(CMD_REMOTE_SUBMIT) "cat step1.previous_links.gz step1.all_vs_new.dir/blast.links.gz step1.new_vs_all.dir/blast.links.gz |\
	gunzip |\
	sort -T $(DIR_TMP) -k1,1 -k3,3n -m |\
	grep -v '#' |\
	gzip" \
	< /dev/null > step1.dir/blast.links.gz
	@touch $@
	$(EPILOG)

step1.clean:
	$(PRELOG)
	@rm -rf step1.all_vs_new.dir step1.new_vs_all.dir
	$(EPILOG)

else
## de novo run
step1.prepare: step1.queries.fasta 
	$(PRELOG)
	@rm -rf step1.dir
	@python $(DIR_SCRIPTS_GENEPREDICTION)gpipe/setup.py \
		-m blast \
		-d step1.dir \
		-p $(PARAM_PROJECT_NAME)_blast \
		-o $(DIR_ROOT) \
		--include=../../data/Makefile.inc \
		PARAM_BLASTP_NUMJOBS=$(PARAM_STEP1_NUMJOBS) \
		PARAM_BLASTP_CHUNKSIZE=$(PARAM_STEP1_CHUNKSIZE) \
		PARAM_BLASTP_OPTIONS="$(PARAM_STEP1_BLASTP_OPTIONS)" \
		PARAM_BLASTP_PARSING="$(PARAM_STEP1_BLASTP_PARSING)" \
		PARAM_BLASTP_NUMFIELDS=$(PARAM_STEP1_BLASTP_NUMFIELDS) \
		PARAM_BLASTP_COMPRESS=1 \
		DIR_TMP=./ \
	> $@
	@ln -s ../step1.queries.fasta step1.dir/queries.fasta
	@ln -s ../step1.queries.fasta step1.dir/sbjcts.fasta
	$(EPILOG)

step1.run: step1.prepare
	$(PRELOG)
	if test -e step1.dir/Makefile; then \
		$(CMD_BENCHMARK) $(MAKE) -C step1.dir -k blast; \
	fi
	@touch $@
	$(EPILOG)

step1.finish:
	$(PRELOG)
	@touch $@
	$(EPILOG)

step1.clean: 
	$(PRELOG)
	$(MAKE) -C step1.dir blast.clean
	$(EPILOG)

endif
## End of alternative step1 processing

###################################################################
## collect sequencies for step1 
step1.queries.fasta: peptides1.fasta peptides2.fasta
	$(PRELOG)
	@cat $^ |\
	python $(DIR_SCRIPTS_TOOLS)gpipe/filter_fasta.py \
		--method=quality \
		--log=$@.log \
		--parameters=$(PARAM_RESTRICT_QUALITY) > $@
	$(PROLOG)

##############################################################################
## check output of step1 (blast.links)
step1.check: 
	$(PRELOG)
	@if [ -e step1.dir/blast.links.gz ]; then \
		grep ">" peptides1.fasta | perl -p -e "s/>//; s/ .*//" > peptides1.ids; \
		grep ">" peptides2.fasta | perl -p -e "s/>//; s/ .*//" > peptides2.ids; \
		gunzip < step1.dir/blast.links.gz |\
		python $(DIR_SCRIPTS_GENEPREDICTION)optic/check_blast_run.py \
		--vertices=peptides1.ids \
		--vertices=peptides2.ids \
		--missed=step1.check.missed \
		> $@; \
		rm -f peptides1.ids peptides2.ids; \
	else \
		$(CMD_MSG2) "no blast.links.gz. Test skipped."; \
	fi
	$(EPILOG)

step1.check2: 
	$(PRELOG)
	if [ -e step1.dir/blast.links.gz ]; then \
		echo -e "# input files" $(TOLOG); \
		grep -c ">" peptides1.fasta peptides2.fasta $(TOLOG); \
		echo -e "# histogram of tokens" $(TOLOG); \
		gunzip < step1.dir/blast.links.gz |\
		perl $(DIR_SCRIPTS_TOOLS)graph_links2tokens.pl |\
		perl -p -e "s/[$(PARAM_SEPARATOR)].*//" |\
		sort -T $(DIR_TMP) | uniq -c $(TOLOG); \
		$(MAKE) step1.dir/blast.link_stats; \
	else \
		$(CMD_LOG2) "no blast.links. Test skipped."; \
	fi
	$(EPILOG)

##############################################################################
##############################################################################
##############################################################################
## Step 2: build the input graph for phyop.
## The blast graph is filtered and weighted.
##############################################################################
ifeq ($(PARAM_STEP2_USE_KS),)

##############################################################################
##############################################################################
##############################################################################
## use normalized bitscore for building the graph
##############################################################################
## filter the graph. Do this on the via the queueing system, but on the head node.
step2: step1 
	$(PRELOG)
	@$(CMD_LOCAL_SUBMIT) $(CMD_BENCHMARK) \
		$(MAKE) step2.self step2.scaled.links.gz step2.seed.links.gz \
	< /dev/null > $@
	$(EPILOG)

##############################################################################
## extract highest self-scores
step2.self: step1
	$(PRELOG)
	@gunzip < step1.dir/blast.links.gz |\
	awk '!/^#/ && $$1 == $$2 { printf("%s\t%s\n", $$1, $$14); }' |\
	sort -T $(DIR_TMP) -k1,1 -k2,2nr |\
	awk '{if (l != $$1) { print; } l = $$1; }' > $@ 
	$(EPILOG)

##############################################################################
## create file with links for orthology assigment
## 	contains normalized bitscore
##	graph is filtered by coverage and normalized bitscore
##	graph is kept symmetric.
step2.scaled.links.gz: step1 step2.self
	$(PRELOG)
	@rm -f $@.log
	@gunzip < step1.dir/blast.links.gz |\
	awk '\
	BEGIN \
		{ while (getline < "step2.self") { a[$$1] = $$2 } } \
		NF == $(PARAM_STEP1_BLASTP_NUMFIELDS) && !/^#/ \
		{ ninput++; \
		cova = ($$5-$$4+1)/$$12; covb = ($$8-$$7+1)/$$13; \
		if (cova > covb) { maxcov = cova; mincov = covb; } \
		else             { maxcov = covb; mincov = cova; } \
		if (!($$1 in a)) { nerrors++;printf("error: %s not found in: %s\n", $$1, $$0) >> "$@.log"; next }; \
		if (!($$2 in a)) { nerrors++;printf("error: %s not found in: %s\n", $$2, $$0) >> "$@.log"; next }; \
		score = (a[$$1] < a[$$2]) ? ($$14 / a[$$1]) : ($$14 / a[$$2]); \
		if ( (mincov < $(PARAM_STEP2_MIN_MIN_COVERAGE)) || (maxcov < $(PARAM_STEP2_MIN_MAX_COVERAGE)) ) \
		{ neliminated_coverage++; next; } \
		if (score < $(PARAM_STEP2_MIN_SCORE)) { neliminated_score++; next; } \
		noutput++; score=1.0-score;\
		if ($$1 < $$2) { \
			printf("%s\t%s\t%8.6f\n",\
			$$1,$$2,score);  \
		} else {\
			printf("%s\t%s\t%8.6f\n",\
			$$2,$$1,score); \
		} \
	      } \
	END \
		{ printf("# ninput=%i, noutput=%i, neliminated_coverage=%i, neliminated_score=%i, nerrors=%i, ", \
			ninput, noutput, neliminated_coverage, neliminated_score, nerrors) >> "$@.log"; } \
	' | sort | uniq |\
	gzip > $@
	@$(MAKE) -s step2.scaled.link_stats
	$(CMD_LOG) "number of pairs with negative scores: `gunzip < $@ | awk '$$3 < 0' | wc -l`"
	$(EPILOG)

##############################################################################
## create file with links for orthology assignment
## * filter by class and distance
## * take only $(PARAM_STEP2_NBESTHITS) links
## * make asymmetric.
step2.seed.links.gz: step2.scaled.links.gz
	$(PRELOG)
	@rm -f  $@.log
	@gunzip < step2.scaled.links.gz |\
	awk -v icodes="$(PARAM_STEP2_QUALITY_SEEDS)" \
		'BEGIN { split(icodes, a, ","); for ( x in a ) { codes[a[x]] = 1; } } \
		       { split($$1,a,"$(PARAM_SEPARATOR)"); \
			 split($$2,b,"$(PARAM_SEPARATOR)"); \
			 ninput++; \
			 if ($$3 > $(PARAM_STEP2_MAX_DISTANCE) ) \
				{ ndiscarded_distance++; next;} \
		         if (a[4] in codes && b[4] in codes) \
				{ noutput++; print;} \
			 else { ndiscarded_class++; } \
		       } \
		END { printf("# ninput=%i, noutput=%i, neliminated_distance=%i, neliminated_class=%i\n", \
			ninput, noutput, ndiscarded_distance, ndiscarded_class ) >> "$@.log" ; } ' |\
	python $(DIR_SCRIPTS_TOOLS)graph2besthits.py \
	$(PYTHON_OPTIONS) \
	--method="distance" \
	--keep-self \
	--nbest=$(PARAM_STEP2_NBESTHITS) |\
	grep -v "#" |\
	sort -T $(DIR_TMP) -k1,1 -k2,2 -k3,3n |\
	awk 'BEGIN {l1=0;l2=0;} {if ($$1 !=l1 || $$2 != l2) {print; l1=$$1;l2=$$2;} }' > $@.tmp
	@ga_components -m step2.seed.components.map -s step2.seed.components.sizes $@.tmp > step2.seed.components
	$(CMD_LOG) "ten largest components in $@: `grep -v "#" step2.seed.components.sizes | cut -f 2 | sort -k1,1n | tail -n 10 | xargs`"
	@gzip < $@.tmp >$@
	@rm -f $@.tmp
	@$(MAKE) -s step2.seed.link_stats
	$(EPILOG)
else
##############################################################################
##############################################################################
##############################################################################
## use ks for building the graph
##############################################################################

step2: step1 step2.prepare step2.run step2.finish
	$(PRELOG)
	@touch $@
	$(EPILOG)

##############################################################################
## filter the blast graph and split for ks computation
##############################################################################
step2.prepare: step2.scaled.links.gz step2.split
	$(PRELOG)
	@$(MAKE) step2.dir
	@touch $@
	$(EPILOG)

##############################################################################
## prepare the blast graph for ks computation
## 1. filter by quality, coverage and score
## 2. symmetrize and filter redundant edges
##############################################################################
CMD_STEP2_SCALED_LINKS=

step2.scaled.links.gz:
	$(PRELOG)
	@rm -f $@.log
	@$(CMD_REMOTE_SUBMIT) \
	$(CMD_BENCHMARK) \
	"gunzip < step1.dir/blast.links.gz |\
	awk -v icodes=\"$(PARAM_STEP2_QUALITY_SEEDS)\" -v sep=\"$(PARAM_SEPARATOR)\" \
	'BEGIN { split(icodes, a, \",\"); for ( x in a ) { codes[a[x]] = 1; } } \
		NF == $(PARAM_STEP1_BLASTP_NUMFIELDS) && !/^#/ \
		{ split(\$$1,a,sep); split(\$$2,b,sep); \
		  ninput++; \
		  if (!(a[4] in codes) || !(b[4] in codes)) \
		  { neliminated_class++; next;} \
		    cova = (\$$5-\$$4+1)/\$$12; covb = (\$$8-\$$7+1)/\$$13; \
		   if (cova > covb) { maxcov = cova; mincov = covb; } \
		   else             { maxcov = covb; mincov = cova; } \
		   score = \$$14; \
		   if ( (mincov < $(PARAM_STEP2_MIN_MIN_COVERAGE)) || (maxcov < $(PARAM_STEP2_MIN_MAX_COVERAGE)) ) \
		   { neliminated_coverage++; next; } \
		   if (score < $(PARAM_STEP2_MIN_SCORE)) { neliminated_score++; next; } \
		   noutput++; \
		   print; \
		   printf (\"%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n\", \
			\$$2, \$$1, \$$3, \$$7, \$$8, \$$9, \$$4, \$$5, \$$6, \$$10, \$$11, \$$13, \$$12, \$$14); \
		} \
	END \
		{ printf(\"# ninput=%i, noutput=%i, neliminated_coverage=%i, neliminated_score=%i, neliminated_class=%i, nerrors=%i, \", \
			ninput, noutput, neliminated_coverage, neliminated_score, neliminated_class, nerrors) >> \"$@.log\"; }' |\
	sort -T $(DIR_TMP) -k1,1 -k2,2 -k3,3n |\
	awk '\$$1 != l1 || \$$2 != l2 { print; l1 = \$$1; l2 = \$$2; }' |\
	gzip > $@"
	@$(MAKE) -s step2.scaled.link_stats
	$(EPILOG)

##############################################################################
## split the blast graph into small chunks for parallel processing
##############################################################################
step2.split: step2.scaled.links.gz
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) \
	"rm -f step2.dir/step2*; \
	gunzip < $< |\
	split -l $(PARAM_STEP2_CHUNKSIZE) -d -a 5 - step2.dir/step2_; \
	for file in step2.dir/step2_*; do mv \$${file} \$${file}.chunk; done" \
	< /dev/null
	@touch $@
	$(EPILOG)


##############################################################################
## perform a kaks computation
##############################################################################
step2%.kaks: step2%.chunk
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) \
	"python $(DIR_SCRIPTS_GENEPREDICTION)links2fasta.py \
	$(PYTHON_OPTIONS) \
	--sequences=<(cat ../cds1.fasta ../cds2.fasta) \
	--map=<(cat ../peptides2cds1 ../peptides2cds2) \
	--codons \
	--nogaps \
	--format=fasta \
	--no-identical \
	--expand \
	--outfile=$@.links \
	--filter=../step2.pairs.old \
	--min-length=$(PARAM_STEP2_MIN_LENGTH) \
	--log=$@.log \
	< $< > $@.tmp; \
	$(CMD_BENCHMARK) \
	seq_pairs_kaks \
	--cdna_sequences $@.tmp \
	--err_log $@.err \
	--aligned \
	--temp_directory /tmp/$@_$$$$ \
	< /dev/null > $@; \
	rm -f $@.tmp;"
	$(EPILOG)

step2.run: step2.prepare
	$(PRELOG)
	@if test -d step2.dir; then \
		$(CMD_BENCHMARK) $(MAKE) -C step2.dir -j $(PARAM_STEP2_NUMJOBS) $@-hook < /dev/null; \
	fi
	@touch $@
	$(EPILOG)

STEP2_QUERIES=$(wildcard step2_*.chunk)
STEP2_TARGETS=$(STEP2_QUERIES:%.chunk=%.kaks)

step2.run-hook: $(STEP2_TARGETS)
	@touch $@

######################################################################
## merge with old results in step2.kaks.old, if they are present
step2.finish: step2.run step2.kaks step2.seed.links.gz
	$(PRELOG)
	@if test -e step2.kaks.old; then \
		mv step2.kaks step2.kaks.new; \
		$(CMD_LOG2) "before merging: links in step2.kaks.new: `wc -l step2.kaks.new`"; \
		$(CMD_LOG2) "before merging: links in step2.kaks.old: `wc -l step2.kaks.old`"; \
		grep -v "#" step2.kaks.old |\
		perl $(DIR_SCRIPTS_TOOLS)graph_filter_links_links.pl -r step2.kaks.new > $@_tmp; \
		cat $@_tmp step2.kaks.new  |\
		perl $(DIR_SCRIPTS_TOOLS)graph_filter_links_links.pl -m step2.kaks.links > step2.kaks; \
		rm -f $@_tmp; \
	fi
	@touch $@
	$(CMD_LOG) "links in step2.kaks: `wc -l step2.kaks`"
	$(EPILOG)

step2.kaks: step2.run
	$(PRELOG)
	@find step2.dir/ -name "step2_*.kaks" -exec cat {} \; > $@ 
	@find step2.dir/ -name "step2_*.kaks.links" -exec cat {} \; > $@.links 
	$(EPILOG)

##############################################################################
## create file with links for orthology assignment
## * filter by ks
step2.seed.links.gz: step2.kaks
	$(PRELOG)
	@rm -f  $@.log
	@cat < step2.kaks |\
	awk '!/^#/ && $$4 < $(PARAM_STEP2_MAX_KS)' | cut -f 1,2,4 > $@.tmp
	@ga_components -m step2.seed.components.map -s step2.seed.components.sizes $@.tmp > step2.seed.components
	$(CMD_LOG) "ten largest components in $@: `grep -v "#" step2.seed.components.sizes | cut -f 2 | sort -k1,1n | tail -n 10 | xargs`"
	@gzip < $@.tmp >$@
	@rm -f $@.tmp
	@$(MAKE) -s step2.seed.link_stats
	$(EPILOG)
endif

################################################
## step3: do pairwise orthology assignments
step3: step2 step3.prepare step3.run step3.finish 
	@touch $@
	$(EPILOG)	

step3.run: step3.prepare
	$(PRELOG)
	@if test -e step3.dir; then \
		$(CMD_BENCHMARK) $(MAKE) -C step3.dir -k all; \
	fi
	@touch $@
	$(EPILOG)

step3.prepare: step2
	$(PRELOG)
	@rm -rf step3.dir
	@python $(DIR_SCRIPTS_GENEPREDICTION)gpipe/setup.py \
		-m orthology \
		-d step3.dir \
		-p $(PARAM_PROJECT_NAME)_orthology \
		-o $(DIR_ROOT) \
		--include=../../data/Makefile.inc \
		PARAM_GENOME1=$(PARAM_GENOME1) \
		PARAM_GENOME2=$(PARAM_GENOME2) \
		PARAM_STEP1_NUMJOBS=$(PARAM_STEP3_NUMJOBS) \
		> $@
	@ln -s ../step2.seed.links.gz step3.dir/filtered.gz
	$(EPILOG)

step3.finish: step3.run step3.genes1 step3.genes2
	$(PRELOG)
	@touch $@
	$(EPILOG)

#####################################################################
#####################################################################
#####################################################################
## Overlapping transcripts are clustered by overlap and orthology.
## A random transcript is chosen as the new gene identifier.
#####################################################################
step3.map_transcripts: step3.run
	$(PRELOG)
	@python $(DIR_SCRIPTS_GENEPREDICTION)optic/orthologs2genes.py \
	$(PYTHON_OPTIONS) \
	$(STEP3_TRANSCRIPTS_OPTIONS) \
	--write-map \
	--filename-exons1=exons1.exons \
	--filename-exons2=exons2.exons \
	< step3.dir/interpretation > $@
	$(EPILOG)

#####################################################################
#####################################################################
#####################################################################
## Remove all genes not in orthologs and assign new genes to overlapping
## transcripts. The longest transcript is again chosen as the representative
## for a gene.
## $@.map_old2new: a map between old transcripts to new transcripts 
## $@.peptides2genes: a map between new transcripts to new genes.
#####################################################################
STEP3_ID=%s$(PARAM_SEPARATOR)%s$(PARAM_SEPARATOR)%s$(PARAM_SEPARATOR)%s
step3.genes%: step3.map_transcripts
	$(PRELOG)
	@grep -v "#" step3.map_transcripts | cut -f 1 > $@.tmp1
	@awk 'BEGIN {while (getline < "$@.tmp1") { map[$$1] = $$2 } } \
	$$1 in map' < exons$*.exons |\
	python $(DIR_SCRIPTS_GENEPREDICTION)gpipe_gpipe/exonerate_combine_regions.py \
	--use-genome-length > $@.tmp2
	@awk '!/^#/ { split( $$1, a, "$(PARAM_SEPARATOR)"); \
		     split( $$2, b, "$(PARAM_SEPARATOR)"); \
		     printf("$(STEP3_ID)\t$(STEP3_ID)\n", \
			b[1],b[2],b[3],b[4], \
			b[1],b[2],a[2],b[4]); }' \
	< $@.tmp2 > $@.map_old2new
	@awk '/^#/ { print; next; } \
		!/^#/ { split( $$1, a, "$(PARAM_SEPARATOR)"); \
		        split( $$2, b, "$(PARAM_SEPARATOR)"); \
		        printf("$(STEP3_ID)\t$(STEP3_ID)\n", \
			a[1],a[2],a[2],a[4], \
			b[1],b[2],a[2],b[4]); }' \
	< $@.tmp2 > $@.peptides2genes
	@rm -f $@.tmp1 $@.tmp2 $@.tmp3
	@touch $@
	$(EPILOG)

##########################################################################
##########################################################################
##########################################################################
## Check result of orthology assignment for completeness
##########################################################################
step3.check: 
	$(PRELOG)
	@target_dir=step3.dir; \
	if [ -e $${target_dir} ] ; then \
	    printf "jobs: started=%i rejoined=%i unchanged=%i\n" \
	    `find $${target_dir}/step1.dir/ -name "*.ks" | wc -l` \
	    `find $${target_dir}/step1.dir/ -name "*.rejoined" ! -empty | wc -l` \
	    `find $${target_dir}/step1.dir/ -name "*.unchanged" ! -empty | wc -l` $(TOLOG); \
	    for file in ortho_1_to_1 ortho_1_to_m ortho_m_to_1 orphaned; do \
		    printf "%-20s : %10i\n" \
			    $${file} \
			    `grep -c -v -e ">" -e "^$$" < $${target_dir}/orthology_$${file}` $(TOLOG); \
	    done; \
	else \
	    echo "$${target_dir} does not exist." $(TOLOG); \
        fi
	@touch $@
	$(EPILOG)

##########################################################################
##########################################################################
##########################################################################
## Clean up temporary data
##########################################################################
step3.clean:
	$(PRELOG)
	$(MAKE) -C step3.dir clean
	$(EPILOG)

#####################################################################
#####################################################################
#####################################################################
## step4: create a list of best hits between sequences
#####################################################################
step4: step1 step4.besthits.links.gz
	@touch $@
	$(EPILOG)	

#####################################################################
## create file with links for orthology assignment.
## This file is needed for the multiple orthology clustering.
step4.besthits.links.gz: step1
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) $(CMD_BENCHMARK) \
	"gunzip < step1.dir/blast.links.gz |\
	sort -T $(DIR_TMP) -k1,1 -k3,3n |\
	python $(DIR_SCRIPTS_TOOLS)graph_blast2besthits.py \
		--method=evalue \
		--pide-factor=10 \
		--score-factor=0.9 |\
		gzip " \
	< /dev/null > $@
	$(EPILOG)

##############################################################################
##############################################################################
##############################################################################
## step5: calculate various statistics
##############################################################################
STEP5_METHODS=orthologs,input,crossassignments,expansion,separation 
# ,orphans,duplications

STEP5_ANALYSIS_OPTIONS=--schema1=$(PARAM_GENOME1) \
			--schema2=$(PARAM_GENOME2) \
			--connection=$(PARAM_PSQL_HOST):$(PARAM_PSQL_DATABASE) \
			--filename-interpretation=step3.dir/interpretation \
			--filename-links=step3.dir/filtered.gz \
			--filename-orphans=step3.dir/orthology_orphaned \
			--filename-kaks=step6.kaks \
			--filename-cds1=cds1.fasta \
			--filename-cds2=cds2.fasta \
			--filename-input1=step5.input1 \
			--filename-input2=step5.input2 \
			--filename-exons1=exons1.exons \
			--filename-exons2=exons2.exons \
			--filename-trees=step3.dir/full_tree \
			--max-duplications=$(PARAM_STEP5_MAX_DUPLICATIONS) \
			--prefix=step5.dir/step5_%s.stats \
			$(PYTHON_OPTIONS)

step5: step3 step5.prepare step5.run step5.finish 
	$(PRELOG)
	@touch $@
	$(EPILOG)	

step5.run: step5.prepare
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) $(CMD_BENCHMARK) \
	python $(DIR_SCRIPTS_GENEPREDICTION)optic/analyze_orthology.py \
		$(STEP5_ANALYSIS_OPTIONS) \
		--methods=$(STEP5_METHODS) \
		< /dev/null > $@
	$(EPILOG)
	@touch $@
	$(EPILOG)

step5.input%: peptides%.fasta
	$(PRELOG)
	@grep ">" peptides$*.fasta | perl -p -e "s/^>//; s/ .*//" > $@
	$(EPILOG)

step5.prepare: step3 step5.input1 step5.input2
	$(PRELOG)
	@$(MAKE) step5.dir
	@touch $@
	$(EPILOG)

step5.finish: step5.run
	$(PRELOG)
	@touch $@
	$(EPILOG)

###############################################################
###############################################################
###############################################################
## step6: calculate kaks between orthologs
###############################################################
STEP6_QUERIES=$(wildcard step6_*.chunk)
STEP6_TARGETS=$(STEP6_QUERIES:%.chunk=%.kaks)

step6: step3 step6.prepare step6.run step6.finish
	$(PRELOG)
	@touch $@
	$(EPILOG)

step6.prepare: step3 step6.orthologs step6.pairs.gz
	$(PRELOG)
	@rm -rf step6.dir
	@$(MAKE) step6.dir
	@split -l $(PARAM_STEP6_CHUNKSIZE) -a 5 <(gunzip < step6.pairs.gz | grep -v "#") step6.dir/step6_
	@for file in step6.dir/step6_*; do mv $${file} $${file}.chunk; done
	@touch $@
	$(EPILOG)

step6.orthologs: step3
	$(PRELOG)
	@$(CMD_BENCHMARK) \
	python $(DIR_SCRIPTS_GENEPREDICTION)optic/orthologs2list.py \
		$(PYTHON_OPTIONS) \
		--log=$@.log \
		< step3.dir/interpretation > $@
	$(EPILOG)

peptides2cds%: peptides%.fasta cds%.fasta
	$(PRELOG)
	$(CMD_REMOTE_SUBMIT) \
	python $(DIR_SCRIPTS_GENEPREDICTION)peptides2cds.py \
		$(PYTHON_OPTIONS) \
	 	--cds=cds$*.fasta \
		--verbose=2 \
		--log=$@.log \
	< peptides$*.fasta > $@
	$(EPILOG)

## get pairwise blast alignments for all orthologs
## Symmetrize graph and filter by orthologs.
## only take the highest scoring pairing for a set of
## transcripts per gene.
step6.pairs.gz: step6.orthologs peptides2cds1 peptides2cds2
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) "gunzip < step1.dir/blast.links.gz |\
	awk '{ print; printf (\"%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\", \
		\$$2, \$$1, \$$3, \$$7, \$$8, \$$9, \$$4, \$$5, \$$6, \$$10, \$$11, \$$13, \$$12, \$$14); }' |\
	perl $(DIR_SCRIPTS_TOOLS)graph_filter_links_links.pl -d \
	step6.orthologs |\
	sort -T $(DIR_TMP) -k1,1 -k2,2 -k10,10nr |\
	awk '{ if (\$$1 != l1 || \$$2 != l2) { print; } l1 = \$$1; l2 = \$$2; }' |\
	python $(DIR_SCRIPTS_GENEPREDICTION)links2fasta.py \
	--sequences=<(cat cds1.fasta cds2.fasta) \
	--map=<(cat peptides2cds1 peptides2cds2) \
	--codons \
	--no-gaps \
	--one-based-coordinates \
	--format=fasta \
	--no-identical \
	--expand \
	--outfile=step6.pairs.links \
	--filter=step6.pairs.old \
	--log=$@.log \
	--min-length=$(PARAM_STEP6_MIN_LENGTH) |\
	gzip" \
	< /dev/null > $@
	$(EPILOG)

step6.run: step6.prepare
	$(PRELOG)
	@if test -d step6.dir; then \
		$(CMD_BENCHMARK) $(MAKE) -C step6.dir -j $(PARAM_STEP6_NUMJOBS) $@-hook < /dev/null; \
	fi
	@touch $@
	$(EPILOG)

step6.run-hook: $(STEP6_TARGETS)

step6%.kaks: step6%.chunk
	@$(CMD_REMOTE_SUBMIT) \
	"python $(DIR_SCRIPTS)mali2kaks.py \
		$(PYTHON_OPTIONS) \
		--pairwise \
		--remove-stops \
		--iteration=pairwise \
		--method=paml \
		--log=$@.log \
	< step6$*.chunk > $@"

######################################################################
## merge with old results in step6.kaks.old, if they are present
step6.finish: step6.run step6.kaks
	$(PRELOG)
	@if test -e step6.pairs.old; then \
		mv step6.kaks step6.kaks.new; \
		$(CMD_LOG2) "before merging: links in step6.kaks.new: `wc -l step6.kaks.new`"; \
		$(CMD_LOG2) "before merging: links in step6.kaks.old: `wc -l step6.kaks.old`"; \
		grep -v "#" step6.kaks.old |\
		perl $(DIR_SCRIPTS_TOOLS)graph_filter_links_links.pl -r step6.kaks.new > $@_tmp; \
		cat $@_tmp step6.kaks.new  |\
		perl $(DIR_SCRIPTS_TOOLS)graph_filter_links_links.pl -m step6.pairs.links > step6.kaks; \
		rm -f $@_tmp; \
	fi
	@touch $@
	$(CMD_LOG) "links in step6.kaks: `wc -l step6.kaks`"
	$(EPILOG)

step6.kaks: step6.run
	$(PRELOG)
	@find step6.dir/ -name "step6_*.kaks" -exec cat {} \; |\
	awk '/^seq1/ {if(!f) {print; f=1;} next;} {print;}' > $@ 
	$(EPILOG)

# make graph symmetric and only take best ks transcript pairs
step6.filtered.kaks: step6.kaks
	awk '{ if ( $$1 < $$2) { x = $$1; $$1 = $$2; $$2 = x } print; }' \
	< step6.kaks |\
	perl -p -e "s/ /\t/g" |\
	sort -T $(DIR_TMP) -k1,1 -k2,2 -k4,4n |\
	awk '{ if ( x == $$1 &&  y == $$2) { next; } print; x = $$1; y = $$2; }' \
	> $@

## minimum ks per gene
step6.ks_per_gene: step6.filtered.kaks
	awk '{ split($$1, a, "$(PARAM_SEPARATOR)"); split($$2, b, "$(PARAM_SEPARATOR)"); \
		printf("%s%s%s\t%s\t%s\n", a[1], "$(PARAM_SEPARATOR)", a[3], "other", $$4); \
		printf("%s%s%s\t%s\t%s\n", b[1], "$(PARAM_SEPARATOR)", b[3], "other", $$4); }' \
	< step6.filtered.kaks |\
	sort -T $(DIR_TMP) -k1,1 |\
	python $(DIR_SCRIPTS_TOOLS)graph_combine_links_redundant.py > $@ 


## clean up
step6.clean:
	$(PRELOG)
	@if [ -s step6.kaks ]; then \
		$(CMD_LOG2) "removing step6.dir."; \
		rm -rf step6.dir; \
	else \
		$(CMD_LOG2) "not removing step6.dir."; \
	fi 
	$(EPILOG)

###############################################################
## step6 progress
step6.show-progress:
	@echo "# prediction status at `date`" >> step6.progress
	@find step6.dir -name "step6_*.kaks" -exec grep "GRAPH: region [0-9]*: finished" {} \; |\
	awk -v total=`grep -c ">" step6.pairs` -v finished=`cat step6.dir/*.kaks | wc -l` \
	' END { printf("done\ttotal\tpercent\n"); \
		printf("%i\t%i\t%5.2f\n", finished, total / 2, 100 * finished / (total/2)); }' \
	>> step6.progress
	@tail step6.progress

###############################################################
###############################################################
###############################################################
## step7: calculate d4 and other sequence distances
###############################################################
step7: step6.pairs.gz step7.prepare step7.run step7.finish 
	@touch $@
	$(EPILOG)	

step7.prepare: step6.pairs.gz
	$(PRELOG)
	@touch $@
	$(EPILOG)

step7.run: step7.prepare step7.pairs
	$(PRELOG)
	@touch $@
	$(EPILOG)

step7.pairs: step6.pairs.gz 
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) \
	"gunzip < $< |\
	grep -v '#' |\
	python $(DIR_SCRIPTS_GENEPREDICTION)fasta2distances.py \
	$(PYTHON_OPTIONS) \
	--fields='aligned,identical,transitions,transversions,jc69,t92' \
	--filter='all,codon3,d4' |\
	perl -p -e 's/ \S+ \S+//g' \
	> $@"
	$(EPILOG)

step7.clean:

#################################################################
## Collect results.
## Merge with previous results from step7.
## Removes redundancy at the end as a patch. The longest aligned 
## pair (field 3) is taken.
step7.finish: step7.run
	$(PRELOG)
	@if test -e step7.pairs.old; then \
		mv step7.pairs step7.pairs.new; \
		$(CMD_LOG2) "before merging: links in step7.pairs.new: `wc -l step7.pairs.new`"; \
		$(CMD_LOG2) "before merging: links in step7.pairs.old: `wc -l step7.pairs.old`"; \
		grep -v "#" step7.pairs.old |\
		perl $(DIR_SCRIPTS_TOOLS)graph_filter_links_links.pl -r step7.pairs.new > $@_tmp; \
		grep "id1.id2" step7.pairs.new > step7.pairs; \
		cat $@_tmp step7.pairs.new |\
		grep -v "#" |\
		perl $(DIR_SCRIPTS_TOOLS)graph_filter_links_links.pl -m step6.pairs.links |\
		sort -T $(DIR_TMP) -k1,1 -k2,2 -k3,3nr |\
		awk '{ if ($$1 != l1 || $$2 != l2) { print; } l1 = $$1; l2 = $$2; }' >> step7.pairs; \
		rm -f $@_tmp; \
		touch step7.run; \
	fi
	@touch $@
	$(CMD_LOG) "links in step6.pairs.links: `wc -l step6.pairs.links`"
	$(CMD_LOG) "links in step7.pairs: `wc -l step7.pairs`"
	$(EPILOG)

###############################################################
###############################################################
###############################################################
## step9: do pairwise orthology assignments based on ks and genes
###############################################################
step9: step6 step9.prepare step9.run step9.finish 
	@touch $@
	$(EPILOG)	

step9.run: step9.prepare
	$(PRELOG)
	@if test -e step9.dir; then \
		$(CMD_BENCHMARK) $(MAKE) -C step9.dir -k all; \
	fi
	@touch $@
	$(EPILOG)

step9.prepare: step6 step9.links
	$(PRELOG)
	@rm -rf step9.dir
	@python $(DIR_SCRIPTS_GENEPREDICTION)gpipe/setup.py \
		-m orthology \
		-d step9.dir \
		-p $(PARAM_PROJECT_NAME)_orthology \
		-o $(DIR_ROOT) \
		--include=../../data/Makefile.inc \
		PARAM_GENOME1=$(PARAM_GENOME1) \
		PARAM_GENOME2=$(PARAM_GENOME2) \
		PARAM_STEP1_NUMJOBS=$(PARAM_STEP9_NUMJOBS) \
		> $@
	@awk '!/^#/ && $$3 <= $(PARAM_STEP9_MAX_DISTANCE) \
		{ printf("%s\t%s\t%s\n", $$1, $$2, $$3); }' \
	< step9.links | gzip > step9.dir/filtered.gz
	$(EPILOG)

STEP9_IDENTIFIER=%s$(PARAM_SEPARATOR)%s$(PARAM_SEPARATOR)%s$(PARAM_SEPARATOR)%s

## Build input graph. Only the lowest scoring ks value is used
## (there can be duplicates due to the ks graph). Also, set
## all distances within genes to 0 and remove genes "0".
##
##
## Optionally: map genes by orthology assignment done previously.
##             otherwise: keep existing gene assignments.
##
##
## Quality code of genes is set to best.
step9.map_gene2quality%: step3.genes%
	$(PRELOG)
ifdef PARAM_STEP9_MAP_GENES
	@grep -v "#" step3.genes$*.map_old2new | cut -f 2 > $@.tmp
else
	@grep ">" peptides$*.fasta | perl -p -e "s/>//; s/ .*//" > $@.tmp
endif
	@python $(DIR_SCRIPTS_GENEPREDICTION)gpipe/genes2quality.py \
	$(PYTHON_OPTIONS) \
	--filter-quality=$(PARAM_STEP2_QUALITY_SEEDS) \
	--infile-transcripts=$@.tmp > $@
	@rm -f $@.tmp
	$(EPILOG)

step9.links: step6.kaks step9.map_gene2quality1 step9.map_gene2quality2
	$(PRELOG)
	@rm -f $@.tmp*
	@gunzip < step2.seed.links.gz |\
	perl $(DIR_SCRIPTS_TOOLS)graph_links2tokens.pl > $@.tmp1
	@cut -f 1,2,4 < step6.kaks > $@.tmp2
	@grep ">" peptides1.fasta | perl -p -e "s/>//; s/ .*//" |\
	python $(DIR_SCRIPTS_GENEPREDICTION)optic/transcripts2links.py \
	$(PYTHON_OPTIONS) \
	--filename-filter=$@.tmp1 \
	--method="genes" >> $@.tmp2
	@grep ">" peptides2.fasta | perl -p -e "s/>//; s/ .*//" |\
	python $(DIR_SCRIPTS_GENEPREDICTION)optic/transcripts2links.py \
	$(PYTHON_OPTIONS) \
	--filename-filter=$@.tmp1 \
	--method="genes" >> $@.tmp2
	@awk '$$3 ~ /identical/ \
		{  printf("%s\t%s\t0\n", $$1, $$2); }' \
	< step6.pairs.links >> $@.tmp2
ifdef PARAM_STEP9_MAP_GENES
	@python $(DIR_SCRIPTS_TOOLS)substitute_tokens.py \
	--apply=<(cat step3.genes1.map_old2new step3.genes2.map_old2new) \
	--filter \
	--columns=1,2 \
	< $@.tmp2 > $@.tmp3
else
	@ln $@.tmp2 $@.tmp3
endif
	@awk -v genome1=$(PARAM_GENOME1) -v genome2=$(PARAM_GENOME2) \
	'BEGIN \
		{ while (getline < "step9.map_gene2quality1") { if(!match($$0, "^#")) { map[1 $$1] = $$4; } } \
		  while (getline < "step9.map_gene2quality2") { if(!match($$0, "^#")) { map[2 $$1] = $$4; } } } \
		!/^#/ && \
		$$1 !~ /[$(PARAM_SEPARATOR)]0[$(PARAM_SEPARATOR)]/ && \
		$$2 !~ /[$(PARAM_SEPARATOR)]0[$(PARAM_SEPARATOR)]/ \
		{ \
			split($$1, a, "$(PARAM_SEPARATOR)"); \
			split($$2, b, "$(PARAM_SEPARATOR)"); \
			if (a[1] == b[1] && a[3] == b[3]) { next; } \
			g1 = a[1] == genome1 ? 1 : 2; \
			g2 = b[1] == genome1 ? 1 : 2; \
			ca = map[g1 a[3]] ? map[g1 a[3]] : "UK"; \
			cb = map[g2 b[3]] ? map[g2 b[3]] : "UK"; \
			printf("$(STEP9_IDENTIFIER)\t$(STEP9_IDENTIFIER)\t%s\n", \
				a[1], a[3], a[3], ca, \
				b[1], b[3], b[3], cb, \
				$$3); \
			printf("$(STEP9_IDENTIFIER)\t$(STEP9_IDENTIFIER)\t%s\n", \
				b[1], b[3], b[3], cb, \
				a[1], a[3], a[3], ca, \
				$$3); \
		}' < $@.tmp3 |\
	sort -T $(DIR_TMP) -k1,1 -k2,2 -k3,3n |\
	python $(DIR_SCRIPTS_TOOLS)graph_combine_links_redundant.py > $@
	$(CMD_LOG) "step9.links: links containing genes with unknown quality: `grep -c 'UK' $@`"  
	@rm -f $@.tmp*
	$(EPILOG)

step9.finish: step9.run
	$(PRELOG)
	@touch $@
	$(EPILOG)

step9.check: 
	$(PRELOG)
	@genomes=( $(PARAM_GENOMES) ); \
	for (( x = 0; x < $(PARAM_NUM_GENOMES) - 1; ++x )); do \
		for (( y = $$x + 1; y < $(PARAM_NUM_GENOMES); ++y )); do \
			target_dir=pair_$${genomes[$$x]}-$${genomes[$$y]}/step9.dir; \
			echo "checking $${target_dir}" $(TOLOG); \
			if [ -e $${target_dir} ] ; then \
				printf "jobs: started=%i rejoined=%i unchanged=%i\n" \
				`find $${target_dir}/step1.dir/ -name "*.ks" | wc -l` \
				`find $${target_dir}/step1.dir/ -name "*.rejoined" ! -empty | wc -l` \
				`find $${target_dir}/step1.dir/ -name "*.unchanged" ! -empty | wc -l` $(TOLOG); \
				for file in ortho_1_to_1 ortho_1_to_m ortho_m_to_1 orphaned; do \
					printf "%-20s : %10i\n" \
						$${file} \
						`grep -c -v -e ">" -e "^$$" < $${target_dir}/orthology_$${file}` $(TOLOG); \
				done; \
			else \
				echo "$${target_dir} does not exist." $(TOLOG); \
			fi; \
		done; \
	done
	@touch $@
	$(EPILOG)

step9.clean:
	$(MAKE) -C step9.dir clean

##############################################################################
## step10: calculate various statistics
##############################################################################
STEP10_METHODS=expansion,orthologs,input,crossassignments,separation 
#,orphans,duplications

STEP10_ANALYSIS_OPTIONS=--schema1=$(PARAM_GENOME1) \
			--schema2=$(PARAM_GENOME2) \
			--connection=$(PARAM_PSQL_HOST):$(PARAM_PSQL_DATABASE) \
			--filename-interpretation=step9.dir/interpretation \
			--filename-links=step9.dir/filtered.gz \
			--filename-orphans=step9.dir/orthology_orphaned \
			--filename-cds1=cds1.fasta \
			--filename-cds2=cds2.fasta \
			--filename-trees=step9.dir/full_tree \
			--filename-exons1=exons1.exons \
			--filename-exons2=exons2.exons \
			--prefix=step10.dir/step10_%s.stats \
			--max-duplications=$(PARAM_STEP10_MAX_DUPLICATIONS) \
			--use-genes \
			--verbose=2 \
			$(PYTHON_OPTIONS) \

step10: step9 step10.prepare step10.run step10.finish 
	$(PRELOG)
	@touch $@
	$(EPILOG)	

step10.run: step10.prepare
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) \
	python $(DIR_SCRIPTS_GENEPREDICTION)optic/analyze_orthology.py \
		$(STEP10_ANALYSIS_OPTIONS) \
		--methods=$(STEP10_METHODS) \
	< /dev/null > $@
	@touch $@
	$(EPILOG)

## Used to be supplied to step10, apparently used for filtering the input
## Why was this necessary?
## I have removed the options for step10
step10.input%: step3 peptides%.fasta
	$(PRELOG)
	@grep ">" peptides$*.fasta | perl -p -e "s/^>//; s/ .*//" |\
	python $(DIR_SCRIPTS_TOOLS)substitute_tokens.py \
		--column=1 \
		--filter \
		--apply=step3.genes$*.map_old2new > $@
	$(EPILOG)

step10.prepare: step9 step10.input1 step10.input2
	$(PRELOG)
	@$(MAKE) step10.dir
	@touch $@
	$(EPILOG)

step10.finish: step10.run
	$(PRELOG)
	@touch $@
	$(EPILOG)

###############################################################
###############################################################
###############################################################
## Compute traces - where do predictions fall out.
###############################################################
step11: step11.run
	$(PRELOG)
	@touch $@
	$(EPILOG)

step11.run: step1 step2 step3 step6 step9 
	$(PRELOG)
	@$(MAKE) -j $(PARAM_NUM_JOBS) step11.run-hook
	@touch $@
	$(EPILOG)

step11.run-hook: step11_$(PARAM_GENOME1).trace step11_$(PARAM_GENOME2).trace

step11_$(PARAM_GENOME1).trace: STEP11_OPTIONS=--schema=$(PARAM_GENOME1) --filename-cds=cds1.fasta
step11_$(PARAM_GENOME2).trace: STEP11_OPTIONS=--schema=$(PARAM_GENOME2) --filename-cds=cds2.fasta

step11_%.trace: step10
	$(PRELOG)
	@$(CMD_REMOTE_SUBMIT) \
	python $(DIR_SCRIPTS_GENEPREDICTION)optic/analyze_orthology_pairwise.py \
		$(PYTHON_OPTIONS) \
		$(STEP11_OPTIONS) \
		--filename-blast=step1.dir/blast.links.gz \
		--filename-bitscore-distances=step2.scaled.links.gz \
		--filename-kaks=step6.kaks \
		--filename-orphans=step3.dir/orthology_orphaned \
		--filename-orphans=step3.dir/orthology_orphaned \
		--filename-orthologs=step9.dir/interpretation \
		--filename-orthologs=step9.dir/interpretation \
	< /dev/null > $@
	$(EPILOG)

step11.finish: step11.run step11.hist

step11.hist: step11_$(PARAM_GENOME1).trace step11_$(PARAM_GENOME2).trace
	$(PRELOG)
	@python $(DIR_SCRIPTS_TOOLS)csv_cut.py stage < step11_$(PARAM_GENOME1).trace |\
	python $(DIR_SCRIPTS_TOOLS)data2histogram.py --headers="$(PARAM_GENOME1)" > $@.tmp1
	@python $(DIR_SCRIPTS_TOOLS)csv_cut.py stage < step11_$(PARAM_GENOME2).trace |\
	python $(DIR_SCRIPTS_TOOLS)data2histogram.py --headers="$(PARAM_GENOME2)" > $@.tmp2
	@python $(DIR_SCRIPTS_TOOLS)combine_histograms.py $@.tmp1 $@.tmp2 > $@
	@rm -f $@.tmp*
	$(EPILOG)

###############################################################
## some statistics:
# do not add dependencies here because of cyclic dependecies
%.link_stats: 
	if test -e $*.links.gz; then \
		prefix="cat $*.links.gz | gunzip "; \
	else \
		prefix="cat $*.links"; \
	fi; \
	echo -e "# summary of graph $*\nqueries\tsbjcts\tvertices\tlinks" $(TOLOG); \
	eval "$${prefix}" | perl $(DIR_SCRIPTS_TOOLS)graph_howmany.pl | grep -v "#" $(TOLOG) ; \
	echo -e "# histogram of tokens" $(TOLOG); \
	eval "$${prefix}" | perl $(DIR_SCRIPTS_TOOLS)graph_links2tokens.pl |\
	perl -p -e "s/[$(PARAM_SEPARATOR)]\S*[$(PARAM_SEPARATOR)]\S+[$(PARAM_SEPARATOR)]/\t/" |\
	sort -T $(DIR_TMP) | uniq -c $(TOLOG)

clean: step1.clean step3.clean step6.clean step7.clean step9.clean

#########################################################################
include $(DIR_SCRIPTS_GENEPREDICTION)/makefiles/Makefile.common
